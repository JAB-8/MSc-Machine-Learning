{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yu4A6Ge6n5q"
      },
      "source": [
        "pip install ctgan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbiFocTICW_7"
      },
      "source": [
        "pip install scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2xx3W3eHQbS"
      },
      "source": [
        "pip install -U imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfekWuwcQK0I"
      },
      "source": [
        "pip install h2o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEWesNWQgxKr"
      },
      "source": [
        "pip install pyro-ppl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdLOiyTrhSL8"
      },
      "source": [
        "!pip install plotly>=4.7.1\n",
        "!wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca\n",
        "!chmod +x /usr/local/bin/orca\n",
        "!apt-get install xvfb libgtk2.0-0 libgconf-2-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc97t5TDiDVX"
      },
      "source": [
        "# Import packages\n",
        "# https://medium.com/pursuitnotes/multiple-linear-regression-model-in-7-steps-with-python-c6f40c0a527\n",
        "# https://scikit-learn.org/stable/inspection.html\n",
        "# https://www.notion.so/Students-Notes-2f5f1b34045f49cab8c8479871a99f12\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from collections import Counter\n",
        "from scipy import interp\n",
        "from scipy.stats import norm\n",
        "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import Perceptron, LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc, f1_score, accuracy_score,recall_score\n",
        "from sklearn import datasets, metrics, model_selection, svm\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.inspection import plot_partial_dependence\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from ctgan import CTGANSynthesizer\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "import pyro.contrib.examples.util  # patches torchvision\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "import csv\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
        "import h2o\n",
        "from tabulate import tabulate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz9pW_n-UY9T"
      },
      "source": [
        "**Data Upload & Processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtKGDrLKyngG"
      },
      "source": [
        "# loading dataset\n",
        "dataset = pd.read_csv('Final_Input.csv')\n",
        "all_policies = (dataset.iloc[:, :].values).astype(np.float)\n",
        "\n",
        "# assigning bucket values to categorical variables based on their score\n",
        "cat_calc = all_policies[:,0:6]\n",
        "cat_calc[cat_calc < 0.2] = 1 \n",
        "cat_calc[cat_calc < 0.4] = 2 \n",
        "cat_calc[cat_calc < 0.6] = 3 \n",
        "cat_calc[cat_calc < 0.8] = 4 \n",
        "cat_calc[cat_calc < 1.0] = 5\n",
        "\n",
        "# normalising between zero and one to match continous variables scale\n",
        "all_policies[:,0:6] = cat_calc/5\n",
        "\n",
        "# creating test and hold out set\n",
        "all_policies_copy = np.copy(all_policies)\n",
        "X_original, X_hold_out, Y_original, Y_hold_out = train_test_split(all_policies_copy[:,:-1], all_policies_copy[:,-1], test_size=0.2, random_state=0)\n",
        "original_policies = np.append(X_original,np.expand_dims(Y_original,1),axis=1)\n",
        "hold_out_policies = np.append(X_hold_out,np.expand_dims(Y_hold_out,1),axis=1)\n",
        "\n",
        "# creating subset array of claim policies only and non claim policies only\n",
        "index = np.where(original_policies[:,-1] == 1)\n",
        "claim_policies = original_policies[index[0],:]\n",
        "index = np.where(original_policies[:,-1] == 0)\n",
        "non_claim_policies = original_policies[index[0],:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTgzagdV1bA9"
      },
      "source": [
        "**Synthetic Data Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU7GMEqS30Y6"
      },
      "source": [
        "Method 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1UxQ4i7q_7J"
      },
      "source": [
        "# METHOD 1 - undersample\n",
        "\n",
        "def undersample(original_policies):\n",
        "  # divide original data into main training set and test set to remain seperate\n",
        "  X_main, X_final_test, Y_main, Y_final_test = train_test_split(original_policies[:,:-1], original_policies[:,-1], test_size=0.2, random_state=0)\n",
        "\n",
        "  # undersample majority class in training and test sets and shuffle\n",
        "  with warnings.catch_warnings():\n",
        "      warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "      undersample = RandomUnderSampler(sampling_strategy=0.2)\n",
        "      X_train, Y_train = undersample.fit_resample(X_main, Y_main)\n",
        "      shuffle = np.arange((X_train.shape[0]))\n",
        "      np.random.shuffle(shuffle)\n",
        "      X_train = X_train[shuffle,:]\n",
        "      Y_train = Y_train[shuffle]\n",
        "\n",
        "      shuffle = np.arange((X_final_test.shape[0]))\n",
        "      np.random.shuffle(shuffle)\n",
        "      X_final_test = X_final_test[shuffle,:]\n",
        "      Y_final_test = Y_final_test[shuffle]\n",
        "\n",
        "      print(sorted(Counter(Y_train).items()))\n",
        "      print(sorted(Counter(Y_final_test).items()))\n",
        "\n",
        "  return X_train, Y_train, X_final_test, Y_final_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_VcaJmJx3xu",
        "outputId": "bd7919e9-c12f-4d5d-f31d-081e7a5f859e"
      },
      "source": [
        "X_train, Y_train, X_final_test, Y_final_test = undersample(original_policies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.0, 375), (1.0, 75)]\n",
            "[(0.0, 1115), (1.0, 19)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF-9acafrIH2"
      },
      "source": [
        "Method 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po7ANwF94NJJ"
      },
      "source": [
        "# METHOD 2 - create synthetic claim policies using CTGAN\n",
        "# https://github.com/sdv-dev/CTGAN & https://arxiv.org/pdf/1907.00503.pdf\n",
        "\n",
        "def CTGAN(original_policies):\n",
        "  # divide original data into main training set and test set to remain seperate\n",
        "  X_main, X_final_test, Y_main, Y_final_test = train_test_split( original_policies[:,:-1], original_policies[:,-1], test_size=0.2, random_state=0)\n",
        "\n",
        "  with warnings.catch_warnings():\n",
        "      warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "      # undersample majority class in training set in preperation for data synthesis\n",
        "      undersample = RandomUnderSampler(sampling_strategy=0.2)\n",
        "      X_resampled, y_resampled = undersample.fit_resample(X_main, Y_main)\n",
        "      resampled_data = np.append(X_resampled,np.expand_dims(y_resampled,axis = 1),axis=1)\n",
        "\n",
        "      # undersample majority class in test set and shuffle\n",
        "      shuffle = np.arange((X_final_test.shape[0]))\n",
        "      np.random.shuffle(shuffle)\n",
        "      X_final_test = X_final_test[shuffle,:]\n",
        "      Y_final_test = Y_final_test[shuffle]\n",
        "\n",
        "  # identify claim and non claim policies in training set and create seperate arrays for each\n",
        "  index = np.where(resampled_data[:,-1] == 1)\n",
        "  temp_claim_policies = resampled_data[index[0],:]\n",
        "  index = np.where(resampled_data[:,-1] == 0)\n",
        "  temp_non_claim_policies = resampled_data[index[0],:]\n",
        "\n",
        "  # Indices of the columns that are discrete\n",
        "  discrete_columns = [0,1,2,3,4,5,(temp_claim_policies.shape[1]-1)]\n",
        "\n",
        "  # Synthetic copy \n",
        "  with warnings.catch_warnings():\n",
        "      warnings.filterwarnings(\"ignore\")\n",
        "      ctgan = CTGANSynthesizer(epochs=300)\n",
        "      ctgan.fit(temp_claim_policies, discrete_columns)\n",
        "      synthetic_data = ctgan.sample(75)\n",
        "  \n",
        "  # append synthetic claim polcies to original non claim policies\n",
        "  data = np.append(temp_non_claim_policies,synthetic_data,axis=0)\n",
        "  data = np.append(data,temp_claim_policies,axis=0)\n",
        "  \n",
        "  # shuffle data and split into X and Y\n",
        "  np.random.shuffle(data)\n",
        "  X_train = data[:, : -1]\n",
        "  Y_train = data[:, -1]\n",
        "\n",
        "  print(sorted(Counter(Y_train).items()))\n",
        "  print(sorted(Counter(Y_final_test).items()))\n",
        "\n",
        "  return X_train, Y_train, X_final_test, Y_final_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUm8khSwyGbU",
        "outputId": "1b5f614f-a1ae-486d-9ce7-9e91c55a39c3"
      },
      "source": [
        "X_train, Y_train, X_final_test, Y_final_test = CTGAN(original_policies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.0, 375), (1.0, 150)]\n",
            "[(0.0, 1115), (1.0, 19)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhv7Gw5632-2"
      },
      "source": [
        "Method 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z4UMTJLukAS"
      },
      "source": [
        "# METHOD 3: over sample from claim policies using SMOTE to create more balanced data set\n",
        "# https://imbalanced-learn.org/stable/over_sampling.html#naive-random-over-sampling & https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/ \n",
        "\n",
        "def Smote_function(original_policies,test_sample_mix = 0.1):\n",
        "  # divide original data into main training set and test set to remain seperate\n",
        "  X_main, X_final_test, Y_main, Y_final_test = train_test_split( original_policies[:,:-1], original_policies[:,-1], test_size=0.2, random_state=0)\n",
        "\n",
        "  # undersample majority class in training and test sets\n",
        "  with warnings.catch_warnings():\n",
        "      warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "      undersample = RandomUnderSampler(sampling_strategy=0.2)\n",
        "      X_resampled, y_resampled = undersample.fit_resample(X_main, Y_main)\n",
        "\n",
        "      # shuffle test set\n",
        "      shuffle = np.arange((X_final_test.shape[0]))\n",
        "      np.random.shuffle(shuffle)\n",
        "      X_final_test = X_final_test[shuffle,:]\n",
        "      Y_final_test = Y_final_test[shuffle]\n",
        "\n",
        "  # oversample minority class\n",
        "  with warnings.catch_warnings():\n",
        "      warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "      X_train, Y_train = SMOTE(sampling_strategy=0.4).fit_resample(X_resampled, y_resampled)\n",
        "      shuffle = np.arange((X_train.shape[0]))\n",
        "      np.random.shuffle(shuffle)\n",
        "      X_train = X_train[shuffle,:]\n",
        "      Y_train = Y_train[shuffle]\n",
        "\n",
        "      print(sorted(Counter(Y_train).items()))\n",
        "      print(sorted(Counter(Y_final_test).items()))\n",
        "  \n",
        "  return X_train, Y_train, X_final_test, Y_final_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6Jc4pYNzLh6",
        "outputId": "694e206c-de05-4762-a319-915479c11780"
      },
      "source": [
        "X_train, Y_train, X_final_test, Y_final_test = Smote_function(original_policies,test_sample_mix = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.0, 375), (1.0, 150)]\n",
            "[(0.0, 1115), (1.0, 19)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro0HdFhdfTUQ"
      },
      "source": [
        "Method 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo1I5Pulj2Uh"
      },
      "source": [
        "# METHOD 4: VAE\n",
        "# training a variational auto encoder based on keras tutorial https://blog.keras.io/building-autoencoders-in-keras.html\n",
        "\n",
        "def VAE_synthesise(original_policies):\n",
        "  # divide original data into main training set and test set to remain seperate\n",
        "  X_main, X_final_test, Y_main, Y_final_test = train_test_split( original_policies[:,:-1], original_policies[:,-1], test_size=0.2, random_state=0)\n",
        "\n",
        "  # undersample majority class \n",
        "  with warnings.catch_warnings():\n",
        "      warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "      undersample = RandomUnderSampler(sampling_strategy=0.2)\n",
        "      X_resampled, y_resampled = undersample.fit_resample(X_main, Y_main)\n",
        "      resampled_data = np.append(X_resampled,np.expand_dims(y_resampled,axis = 1),axis=1)\n",
        "\n",
        "      # shuffle test data\n",
        "      shuffle = np.arange((X_final_test.shape[0]))\n",
        "      np.random.shuffle(shuffle)\n",
        "      X_final_test = X_final_test[shuffle,:]\n",
        "      Y_final_test = Y_final_test[shuffle]\n",
        "\n",
        "  # identify claim and non claim policies in training set and create seperate arrays for each\n",
        "  index = np.where(resampled_data[:,-1] == 1)\n",
        "  temp_claim_policies = resampled_data[index[0],:].astype(np.single)\n",
        "  index = np.where(resampled_data[:,-1] == 0)\n",
        "  temp_non_claim_policies = resampled_data[index[0],:]\n",
        "\n",
        "  # set up variables for VAE\n",
        "  original_dim = original_policies.shape[1] - 1\n",
        "  intermediate_dim = 10\n",
        "  latent_dim = 4\n",
        "\n",
        "  inputs = keras.Input(shape=(original_dim,))\n",
        "  h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
        "  z_mean = layers.Dense(latent_dim)(h)\n",
        "  z_log_sigma = layers.Dense(latent_dim)(h)\n",
        "\n",
        "  # define sampling function\n",
        "  def sampling(args):\n",
        "      z_mean, z_log_sigma = args\n",
        "      epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
        "                                mean=0., stddev=0.1)\n",
        "      return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "  z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
        "\n",
        "  # Create encoder\n",
        "  encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "\n",
        "  # Create decoder\n",
        "  latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "  x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "  outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
        "  decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "  # instantiate VAE model\n",
        "  outputs = decoder(encoder(inputs)[2])\n",
        "  vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
        "\n",
        "  reconstruction_loss = keras.losses.mean_squared_error(inputs, outputs)\n",
        "  reconstruction_loss *= original_dim\n",
        "  kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
        "  kl_loss = K.sum(kl_loss, axis=-1)\n",
        "  kl_loss *= -0.5\n",
        "  vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "  vae.add_loss(vae_loss)\n",
        "  vae.compile(optimizer='adam')\n",
        "\n",
        "  # fit VAE\n",
        "  vae.fit(temp_claim_policies[:,:-1], temp_claim_policies[:,:-1],epochs=750,batch_size=20)\n",
        "\n",
        "  # create new synthetic policies\n",
        "  data = np.copy(resampled_data)\n",
        "  n = 3\n",
        "  grid_x = np.linspace(-1, 1, n)\n",
        "  grid_y = np.linspace(-1, 1, n)\n",
        "  grid_z = np.linspace(-1, 1, n)\n",
        "  grid_t = np.linspace(-1, 1, n)\n",
        "\n",
        "  synthetic_data = np.zeros((n**4,original_policies.shape[1]-1))\n",
        "\n",
        "  k = 0\n",
        "  for i, yi in enumerate(grid_x):\n",
        "      for j, xi in enumerate(grid_y):\n",
        "        for z, zi in enumerate(grid_z):\n",
        "          for t, ti in enumerate(grid_t):\n",
        "            z_sample = np.array([[xi, yi, zi, ti]])\n",
        "            x_decoded = decoder.predict(z_sample)\n",
        "            synthetic_data[k,:] = x_decoded[0]\n",
        "            k += 1\n",
        "\n",
        "  # append to original data\n",
        "  synthetic_data = np.append(synthetic_data,np.ones((synthetic_data.shape[0],1)),axis=1)\n",
        "  data = np.append(resampled_data,synthetic_data,axis=0)\n",
        "\n",
        "  # shuffle\n",
        "  np.random.shuffle(data)\n",
        "  X_train = data[:, : -1]\n",
        "  Y_train = data[:, -1]\n",
        "\n",
        "  return X_train, Y_train, X_final_test, Y_final_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujUqWSVA0Mpe"
      },
      "source": [
        "X_train, Y_train, X_final_test, Y_final_test = VAE_synthesise(original_policies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4RITbSs94S1",
        "outputId": "0c1d14d6-c1e1-49b7-87f6-14328bff14ce"
      },
      "source": [
        "  print(sorted(Counter(Y_train).items()))\n",
        "  print(sorted(Counter(Y_final_test).items()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.0, 750), (1.0, 331)]\n",
            "[(0.0, 1115), (1.0, 19)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JcqDL6xUJVb"
      },
      "source": [
        "**PCA Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "NDgrg8uMsQli",
        "outputId": "dcff512f-492c-4328-8ecd-5f6dd81ffa5f"
      },
      "source": [
        "# plotting principal compnent against proportion of variance explained\n",
        "# https://blog.bioturing.com/2018/06/18/how-to-read-pca-biplots-and-scree-plots/\n",
        "\n",
        "pca = PCA(n_components=10)\n",
        "pca.fit(all_policies[:,:-1])\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(sum(pca.explained_variance_ratio_))\n",
        "\n",
        "# https://www.datasklr.com/principal-component-analysis-and-factor-analysis/principal-component-analysis\n",
        "\n",
        "PC_values = np.arange(pca.n_components_) + 1\n",
        "\n",
        "# plt.plot(PC_values, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
        "plt.title('Scree Plot')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Proportion of Variance Explained')\n",
        "plt.plot(PC_values, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
        "plt.savefig('PCA.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2167357  0.13727748 0.1090954  0.0834528  0.0760339  0.07289891\n",
            " 0.07046366 0.06768415 0.05284444 0.03452628]\n",
            "0.9210127211113761\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "TjgO1NDKo8fY",
        "outputId": "16b5673c-4415-4e94-a837-a85a969309a1"
      },
      "source": [
        "# Plot principal components against each other - https://plotly.com/python/pca-visualization/\n",
        "\n",
        "undersample = RandomUnderSampler(sampling_strategy=1)\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    X_PCA, y_PCA = undersample.fit_resample(original_policies[:,:-1], original_policies[:,-1])\n",
        "\n",
        "# fit and transform pca\n",
        "features = [\"1\", \"2\", \"3\"]\n",
        "n_components = 3\n",
        "pca = PCA(n_components=n_components)\n",
        "pca.fit(X_PCA)\n",
        "components = pca.fit_transform(X_PCA)\n",
        "labels = y_PCA.T \n",
        "\n",
        "# plot graphs\n",
        "fig = px.scatter_matrix(components,labels=labels,dimensions=range(n_components),color=labels)\n",
        "fig.update_traces(diagonal_visible=False)\n",
        "fig.write_image(\"PCA_plot.png\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_core.py:79: FutureWarning:\n",
            "\n",
            "Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"480b43c6-2539-46f9-bfe4-8a57d53bc53a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"480b43c6-2539-46f9-bfe4-8a57d53bc53a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '480b43c6-2539-46f9-bfe4-8a57d53bc53a',\n",
              "                        [{\"diagonal\": {\"visible\": false}, \"dimensions\": [{\"axis\": {\"matches\": true}, \"label\": \"0\", \"values\": [-0.02158053110630874, 0.10387014850687089, 0.09827219536626702, -0.5524530521966761, -0.04172482361885532, -0.046186709467546716, -0.2509846141639632, -0.16103309714325212, 0.16828841639583472, 0.08002264981182435, -0.047866821247815154, -0.10623286800783065, 0.8105913292242161, -0.0641721369896232, 0.3509800323560707, 0.38238040547472535, -0.23214515650524314, 0.3957345775231497, 0.2461844597858071, -0.18854772390830862, -0.513536593059339, 0.13191897218287682, -0.2513188106441247, 0.2823584241218343, -0.07684510936835458, -0.14243309621594785, -0.14258409973605932, -0.2825931650212853, -0.13772064017446953, -0.011310864568421852, 0.11339736072267992, -0.004827552546855478, -0.5012054544779836, -0.550357376173535, 0.02100459071809705, -0.12703862310825828, -0.2690765438234546, -0.4004222295746506, -0.2074710401279363, -0.018209182870829874, 0.00045811603535952255, -0.6483584690401236, -0.050283924077058194, -0.11662583229756104, -0.009700247453712714, -0.3250291772024045, 0.26215309733595366, 0.0008525708343298735, -0.05672421488225749, -0.5202354826764098, 0.4853123545162611, 0.2467619772089791, -0.09062135250785912, -0.10048797735027801, -0.1752944323187922, -0.5550039758622427, -0.040745052405460294, -0.01731622690980196, -0.008394301296645085, -0.15590278692988332, -0.31751209567347466, -0.0108919505634552, -0.3038015389377195, -0.17638628182703295, 0.004370740927613503, -0.08966842477482055, 0.04011122050209281, -0.6360272725037633, -0.2023629711819495, -0.46285317826358713, -0.15194400638887656, -0.2011959245748639, -0.4820911310589876, 0.5985692710185769, -0.15744884932978015, 0.01198091354304666, 0.1411277153763553, -0.2368626787531625, -0.7049250624773836, -0.2573051657629823, 0.016307804773045206, -0.6570245796823913, -0.19228132442902304, -0.042826860852849306, -0.30052232022710684, 0.15382479167946886, -0.08692218603917751, 0.08605929406677315, -0.0027248301079593105, 0.034457535117464744, -0.6160017231412331, -0.06820655057983058, 0.11424537511292174, 0.11616569878645437, 0.04192936889378799, -0.012270218799117081, -0.025656775762547913, -0.5920143512122295, -0.00044966125483619237, -0.026848957348919303, 0.06608151759427461, -0.026132120349929414, -0.04970623836121646, -0.4707779160582402, -0.03144288780888924, -0.0959986989046314, -0.05033388730279498, -0.14113907276653923, -0.5664730497147669, -0.011315023450140377, 0.13738193250133793, 0.42299572732064367, -0.2391739424977069, 0.1007906417745772, -0.0493208172543735, -0.05276339462816141, 0.12506824805005395, -0.05167479649504493, -0.0540117071406798, 0.0486238295645471, -0.009903767264768538, -0.07857651666472838, 0.005440425895744904, -0.018224199100566198, -0.21179553783969854, 0.042659062633039715, -0.013508747924134357, -0.059928562160458033, -0.006846278272811777, 0.1692371754804757, 0.3219728938114246, 0.24802254277686428, -0.000472415905750672, -0.16342987959942484, -0.04157091207680089, 0.3192991487743666, 0.10047038545742742, -0.017555091207420017, -0.06281553244786205, 0.348713774329447, 0.8310062886593079, -0.01625370147613056, 0.14029202610037264, 0.41458939501739384, 0.8663293729927719, 0.06545233946265493, 0.46233823751089637, 0.3797003477407287, -0.08320861169781248, 0.3441947744229803, 0.44003507838793243, 0.0356573631324717, 0.2069582085536877, 0.5931320397926045, 0.32523919838697474, 0.013999844020779275, 0.30049523326789424, 0.10168860832088847, 0.07141334758990396, 0.14734579498640388, -0.007636786502323428, 0.34974781845314723, -0.03005941202959399, 0.07139465327023835, 0.4724196771722737, -0.0041161426657054315, 0.07476747619084444, -0.024098844728054587, 0.27075109029724603, -0.08739047590578652, -0.09319141035546558, 0.41855168386985964, 0.8932247881312467, -0.05098881753219877, -0.002727111815786328, -0.06839256266054734, 0.13719986160437633, 0.01900708006975744, -0.4924040432710073, -0.022553911466973216, -0.07325763533512906, 0.5640609314270448, -0.15749495995316976, -0.03956965404669541, 0.0685688616425781, -0.10634331435374178, -0.09727989162183084, 0.011122806120080604, -0.009656208509440664, -0.026629347493503888, -0.21722340219407427, -0.05395791240193141, -0.0861561257689824, -0.009200426028774125, 0.31948884936746924, -0.5024294436254005, -0.005353482914220354, 0.023203435284766333, 0.10601562335742484, -0.034533857832964004, -0.44973975524650467, -0.07252532833224055, 0.38418494963315697, -0.03905392011587653, -0.1522368955625466, 0.3430141435941183, -0.03908279798926141, -0.0570689798137248, -0.09716174394596816, -0.07497690387668543, 0.1410944616968407, 0.016349826642797976, -0.06529676284816083, -0.0394183672540652, 0.0838785914123142, 0.026073723255328387, -0.03766301655036848, -0.012869749206179034, 0.052830371208503875, -0.1194427298959741, 0.2961660483114705, -0.10159416885468087, 0.016562289355106185, 0.28080556749016594, 0.7261218486341761, 0.3557422070648103, 0.21979878620981458, 0.11828726432549813, 0.308932498838738, -0.08232902193678018, 0.4204188225875035, -0.03897151573188304, 0.35955735029435126, 0.00639878606933995]}, {\"axis\": {\"matches\": true}, \"label\": \"1\", \"values\": [-0.21722007646160563, -0.0037095476263010107, -0.032252523646969615, 0.40279724551618573, -0.18765156178610662, -0.23291602163577804, 0.6190692339001289, -0.12761942837833942, -0.15670833457983993, 0.0826072282234059, -0.2226796292035262, -0.1327073524021203, 0.43736534768366947, 0.12383826668045064, 0.11050388078423785, 0.15778359036042922, 0.16523589403964714, 0.2055119739825413, 0.4082876024356877, -0.04444310708320262, 0.5841432745710773, -0.00629475908697765, 0.00510108828374248, 0.08277032037905994, -0.17086567570609157, -0.0891174593990628, -0.09984575191542681, -0.1724076047385342, -0.12839740608886668, -0.07884676283553431, -0.07748721781136063, 0.15400621677888515, 0.586948677291422, 0.4501424844276447, 0.0016885665297591912, -0.169049081648327, 0.05630489213548395, 0.5780640112966849, -0.02185496478134363, -0.25534573939005833, -0.2608601843291872, 0.4460138966016131, -0.21734329454843732, -0.18259368149024174, -0.18016505645541378, 0.0648786787738844, 0.06195482318762227, 0.06727807844783781, -0.20404076790046827, 0.5199531684209887, 0.6198113205800608, -0.012326646784926119, -0.21464194766568448, -0.15696664770287477, -0.16272609658528667, 0.40734275913637913, -0.1556684252262895, -0.09039134724174636, 0.1423453340923241, 0.3339203615372744, 0.08859555792106066, -0.23335896370772394, 0.1059387903570934, -0.11276066716063708, 0.02992987912736741, -0.15608676893400708, 0.06851276140084452, 0.40529624976128664, -0.045980543540221214, 0.6556798386219855, -0.09721045765639057, -0.04376699836826095, 0.10228252072617075, 0.22068255965025482, -0.052451153501219754, -0.2043403039287018, 0.02055294065555992, 0.0780746192222745, 0.4532700927272779, -0.0034993821062657736, -0.08920125957799202, 0.4346817993789015, -0.03272950493076648, -0.22263425816673377, 0.12069086819943736, 0.020429502485855525, -0.2027951218822534, 0.06505847967760044, -0.19265727047920114, -0.2750903408780532, 0.41225390002584167, -0.2236888340443541, -0.116063497982158, -0.011800519182269147, 0.8344543322549272, -0.21078189557687269, -0.2012596497138313, 0.402985377797397, -0.22712319099682984, -0.2118154747078908, -0.036154998966232886, -0.04606485876357111, -0.113193482386278, 0.5556565651657029, -0.20919412471559723, -0.21566812092452348, -0.1693907879556286, -0.06531375747471803, 0.22861863522818118, -0.27136372644327456, 0.3623439960784944, 0.2750836280202117, 0.3468534847225454, 0.027331597083674927, -0.19344556656733666, -0.15599527018714135, 0.008001678086557424, -0.2385527242842299, -0.22471291769415377, -0.2799433051004904, 0.4316868303764812, -0.20156398052087796, -0.11444072217910815, -0.19427326804757636, -0.11010460329901542, -0.05749780813050077, -0.2403034627185193, -0.16805949878710819, -0.26570704164450737, -0.09299398116840943, 0.14122223167447218, 0.04712570621971013, -0.186472112107092, -0.12883039810527985, -0.1848619727651725, 0.08724513020114154, -0.003030739710048675, -0.2386840400668597, -0.25019618948028255, 0.2577084329007061, 0.36842263057482066, -0.2586450192899279, 0.17721382743914738, 0.18623658975926397, 0.33330627030303284, -0.0994579608769905, 0.191594523224214, 0.24385554070959542, -0.2296440069976758, 0.09719528887763075, 0.19316152389737315, -0.32889918815731806, 0.2263952935534855, 0.22831311364223827, 0.04351399212744426, -0.2873427731945939, 0.12722487942392877, -0.027393599952583104, -0.040473980342744735, -0.07786516965068507, -0.25108413241604144, 0.060518136459699765, -0.21547865759161527, -0.12823161992025872, 0.2025566746731842, -0.24513491561922635, -0.004495571605372903, -0.32297093690224365, 1.0784423917225736, -0.1600869228087996, -0.17062779559553862, 0.08305433520148628, 0.30194047856579026, -0.22461459979721288, -0.29536057385328873, -0.1878873231351188, -0.06456127227437192, -0.2521769864513944, 0.3818666545982032, -0.251167897940939, -0.16626320398177383, 0.6595591952282995, -0.07898748626467084, -0.2553480766844962, -0.022670520766042444, -0.0657258415575233, -0.17132439030819088, -0.280148003118907, -0.26141430652514674, -0.2451073818110127, 0.013880823664676875, -0.20088064875207393, -0.18021103728181806, -0.26793612794952704, 0.0955857321757503, 0.34899309099036535, -0.17958115736601243, -0.11133003409093424, 0.012780262975089723, -0.23429543111266474, 0.5309139320398135, -0.163050641893852, 0.09024629236729527, -0.2022538574633767, -0.14891203566352823, -0.04776999216294669, -0.3036697181102702, -0.17778164554578352, -0.12531638000541362, -0.21564762970786533, -0.03419128302451391, -0.2365176931334474, -0.19286598806802394, -0.18410464999774936, -0.019470331483231473, -0.11427563952467916, -0.22155566719846093, -0.19893950171293504, -0.2943299293973414, -0.11488926437798859, 0.19711890033050408, -0.18853711096751766, 0.1853012901785378, -0.018204558288274383, 0.27514122299465954, 0.2188101133490303, 0.2931245185003063, 0.029798014356064526, 0.051754915884768174, -0.2017574533123867, 0.12856034343150954, -0.23469813151568755, 0.20652604327603, -0.2550057644710922]}, {\"axis\": {\"matches\": true}, \"label\": \"2\", \"values\": [0.008209612697759779, -0.0474074944034964, -0.37093784464479024, -0.059523617552131466, 0.19522091451939863, -0.1511730213747621, 0.25417079269673004, -0.003843299119865178, 0.05615661633361743, -0.16895533282489794, -0.10288371736972694, -0.02045792065516281, 0.18924174185058143, -0.12602281530316095, -0.31719682642482316, 0.0460842888846857, -0.15038907762263384, -0.19535896956263857, 0.1869420456170547, 0.044347640499658905, 0.3856297869767443, 0.1927826797538133, 0.25078514395995943, -0.007126480716868365, 0.15853537284207175, 0.04878492313044845, 0.33353468159773075, -0.2402020912871334, -0.1185953918264135, -0.31860045049773744, -0.37424029752888804, 0.009893250220677432, -0.10495589163622081, -0.39185900176027627, -0.04376228372837878, -0.09432356273004965, -0.1394543818623971, -0.21355494778187034, 0.22770247439026312, -0.2814172035686273, 0.10646159824039665, 0.040927146726816785, 0.0058804877926485555, -0.026908280282901396, 0.3837638814841623, -0.19351085691297648, 0.11788735471925697, 0.406740397803736, 0.09748954645255199, 0.398475427897063, 0.23532444050400514, 0.18736530596697817, -0.07971914229796902, 0.2793907448183613, -0.0637173600146243, -0.036759903314680265, 0.31229876576823395, -0.09003545013808964, 0.3674344340224119, -0.10848902178028194, -0.19706027682067045, -0.08293615884544409, 0.15054929802714676, -0.08750626958502189, -0.37719476025653786, 0.18741653416146284, -0.01647874322919702, -0.2342991289388565, 0.011025364379538922, 0.4390699880273589, -0.1426181303534055, -0.10086019409824103, -0.1817944737241568, -0.0509692532720248, 0.15223934451569363, 0.05921043701731143, -0.03354124239948735, 0.04667359523182978, 0.3004293691778492, 0.015701671887307467, -0.05371344689491836, -0.08378889982903735, -0.15557819999224767, 0.0060715456529292925, 0.32894317476379586, -0.20743672894520046, -0.2966850047495751, 0.04284433984918793, 0.1238935336017045, 0.35507398237301285, -0.04570053875897143, -0.0704669703315113, 0.20360028381878495, 0.3048397736433682, -0.05926306180832139, -0.030409738868892342, 0.23169754885737076, 0.004935300164675778, 0.07921785656904921, 0.06369022994384181, -0.2243087330277216, 0.31086316071575737, 0.13197549723508123, -0.422575270613328, -0.05521421870190674, -0.28290768072668243, 0.31610033216954636, 0.03408683377527041, -0.29236439141053205, -0.09959633047211232, -0.14235137974132325, -0.22124212613005276, -0.12057756817079408, -0.3658465361131948, 0.11839288186071378, 0.14204279815826817, 0.11672007774101129, -0.178469345365087, 0.3345476182345939, 0.23406925754508565, -0.07629607618764508, 0.0359832946808407, -0.0068905218027578066, 0.3154704820454712, 0.17682874481782657, -0.08150248325352327, -0.022976798886034485, 0.2578219249081539, -0.21621192861046598, 0.020852697107944417, 0.25227851284026637, -0.04854501099595551, 0.07854354895256285, -0.07318223376917998, 0.2724534837145592, 0.2337391984623368, -0.1661183816417878, 0.14622881159878176, -0.2483875233520339, -0.18879675206901092, -0.1364762757718473, -0.2930811231300188, 0.0812711459003261, -0.07179458329117028, -0.13865957046512137, 0.1010178803344302, -0.02922647218038908, -0.04459220067302408, 0.010654352826696432, 0.4107038974912054, 0.14251776287378834, -0.0241945972639829, 0.047555248461953484, 0.021953065512250732, -0.024571113990940967, -0.11467568306961314, 0.35641655660270394, -0.07864323004837452, -0.08989704538365437, 0.02240568036671825, -0.2993721572945442, 0.04964967493077702, -0.13002028247676406, -0.3378491792430675, 0.27700494735049264, -0.32894859575157315, -0.06856447193949623, -0.23918168008942164, 0.03125042431646748, 0.21742381711965134, 0.20230120972073443, -0.29061378576693514, -0.09802026658900755, -0.08092570506190541, -0.16791780614533636, 0.17392009870595465, -0.20862215473927598, 0.2401097914952498, 0.07600694197962347, -0.06581606251727257, 0.2854039641600622, -0.16321891484434553, 0.2860493099091459, -0.2813793427515899, -0.2251519037957754, 0.2438224469362933, 0.014226973534316201, -0.18833829134279823, -0.099706026158116, -0.1986451911074813, 0.10133207087762833, 0.18751331294862617, -0.2818637988976582, -0.06315955704525196, 0.006774174873662517, -0.3449307892828478, 0.3937139912861546, -0.23946218695369184, 0.4813737132555552, -0.1029480005930999, -0.24784841479534514, 0.32593129584398517, 0.17882120942111607, 0.16502056272528515, -0.13346041284339696, -0.28843958455897, -0.04782094658337326, -0.0941039063283583, 0.23416548726423936, -0.13921140919715205, -0.4364886003707969, 0.01341370056854588, 5.73439525364119e-05, 0.1505058650137406, -0.08436341488133726, 0.14417368334134503, -0.027005340079121372, 0.007903866314245354, 0.17046965166621345, 0.21564277459152495, 0.43867440307684935, 0.23721051568108678, -0.015284187970214568, -0.1875614921212908, -0.1735004261936639, -0.08277781288954518, 0.15948578457116774, -0.23673263049865775, 0.1712718020932406, -0.2019150634972964, -0.1743652663695212, -0.208453359005186, -0.06873001823166054, -0.15612944495354963]}], \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}<br>color=%{marker.color}\", \"legendgroup\": \"\", \"marker\": {\"color\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"coloraxis\": \"coloraxis\", \"symbol\": \"circle\"}, \"name\": \"\", \"showlegend\": false, \"type\": \"splom\"}],\n",
              "                        {\"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"color\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"dragmode\": \"select\", \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('480b43c6-2539-46f9-bfe4-8a57d53bc53a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlvkrCh6UiIR"
      },
      "source": [
        "**Supervised Algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsfnyrr3e3BS"
      },
      "source": [
        "Sklearn algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcQYPLQicj3v"
      },
      "source": [
        "def classification(probs,c):\n",
        "  preds = np.zeros((len(probs)))\n",
        "  i = 0\n",
        "  while i < len(probs):\n",
        "    if probs[i] < c:\n",
        "      preds[i] = 0\n",
        "    else:\n",
        "      preds[i] = 1\n",
        "    i += 1\n",
        "  return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfSGPyk7MWat"
      },
      "source": [
        "# iterate through series of classifers, training and then applying to test set\n",
        "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html\n",
        "\n",
        "# under sampling or data synthesisers to use to balance data\n",
        "data_generators = [undersample, CTGAN, Smote_function,VAE_synthesise]\n",
        "\n",
        "# machine learning algorithms to test\n",
        "names = [\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\n",
        "         \"Random Forest\", \"AdaBoost\"]\n",
        "classifiers = [\n",
        "    LogisticRegression(class_weight='balanced'),\n",
        "    SVC(kernel=\"linear\", C=1, class_weight='balanced'),\n",
        "    SVC(gamma='scale', C=1, class_weight='balanced'), \n",
        "    Perceptron(class_weight='balanced'),\n",
        "    DecisionTreeClassifier(), \n",
        "    RandomForestClassifier(), \n",
        "    AdaBoostClassifier()]\n",
        "\n",
        "# number of splits for cross validation\n",
        "n_splits = 5\n",
        "\n",
        "# creating arrays to store output performance metrics\n",
        "f1_train = np.zeros((len(classifiers),n_splits,len(data_generators)))\n",
        "f1_val = np.zeros((len(classifiers),n_splits,len(data_generators)))\n",
        "f1_test = np.zeros((len(classifiers),1,len(data_generators)))\n",
        "\n",
        "AUC_train = np.zeros((len(classifiers),n_splits,len(data_generators)))\n",
        "AUC_val = np.zeros((len(classifiers),n_splits,len(data_generators)))\n",
        "AUC_test = np.zeros((len(classifiers),1,len(data_generators)))\n",
        "\n",
        "acc_train = np.zeros((len(classifiers),n_splits,len(data_generators)))\n",
        "acc_val = np.zeros((len(classifiers),n_splits,len(data_generators)))\n",
        "acc_test = np.zeros((len(classifiers),1,len(data_generators)))\n",
        "\n",
        "recall_train = np.zeros((len(classifiers),n_splits,len(data_generators)))\n",
        "recall_val = np.zeros((len(classifiers),n_splits,len(data_generators)))\n",
        "recall_test = np.zeros((len(classifiers),1,len(data_generators)))\n",
        "\n",
        "# iterate through each data syntheiser function\n",
        "g = 0\n",
        "for gen in data_generators:\n",
        "  print(gen)\n",
        "\n",
        "  # use data synthesiser function to set up training and test data sets\n",
        "  X_train, Y_train, X_final_test, Y_final_test = gen(original_policies)\n",
        "\n",
        "  # iterate through each machine learning algorithm\n",
        "  i = 0\n",
        "  for name, clf in zip(names, classifiers):\n",
        "    j = 0\n",
        "\n",
        "    # create split function to divide data between training and validation sets\n",
        "    rs = ShuffleSplit(n_splits=n_splits, random_state=0, test_size=0.2, train_size=None)\n",
        "\n",
        "    # perform n_splits cross validation runs on the training data\n",
        "    for train_index, test_index in rs.split(X_train):\n",
        "      X_t = X_train[train_index]\n",
        "      Y_t = Y_train[train_index] \n",
        "      X_val = X_train[test_index]\n",
        "      Y_val = Y_train[test_index] \n",
        "\n",
        "      # fit the machine learning algorithm to the training data\n",
        "      clf.fit(X_t, Y_t)\n",
        "\n",
        "      # make predictions on the training and validation sets\n",
        "      preds_t = clf.predict(X_t)\n",
        "      preds_val = clf.predict(X_val)\n",
        "\n",
        "      # update performance metric arrays\n",
        "      f1_train[i,j,g] = f1_score(Y_t,preds_t)\n",
        "      f1_val[i,j,g] = f1_score(Y_val,preds_val)\n",
        "\n",
        "      AUC_train[i,j,g] = roc_auc_score(Y_t,preds_t)\n",
        "      AUC_val[i,j,g] = roc_auc_score(Y_val,preds_val)\n",
        "\n",
        "      acc_train[i,j,g] = accuracy_score(Y_t,preds_t)\n",
        "      acc_val[i,j,g] = accuracy_score(Y_val,preds_val)\n",
        "\n",
        "      recall_train[i,j,g] = recall_score(Y_t,preds_t)\n",
        "      recall_val[i,j,g] = recall_score(Y_val,preds_val)\n",
        "\n",
        "      j += 1\n",
        "    \n",
        "    # fit on entire training set and make predictions on test set\n",
        "    clf.fit(X_train, Y_train) \n",
        "    preds_test = clf.predict(X_final_test)\n",
        "\n",
        "    # update test set performance metrics\n",
        "    f1_test[i,0,g] = f1_score(Y_final_test,preds_test)\n",
        "    AUC_test[i,0,g] = roc_auc_score(Y_final_test,preds_test)\n",
        "    acc_test[i,0,g] = accuracy_score(Y_final_test,preds_test)\n",
        "    recall_test[i,0,g] = recall_score(Y_final_test,preds_test)\n",
        "\n",
        "    i += 1  \n",
        "  g += 1     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwN_ps9Bhdha"
      },
      "source": [
        "Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRabteNABFHR",
        "outputId": "6e83dabf-43c3-4e6e-9b2a-e2af6a664fb0"
      },
      "source": [
        "# calculating AUC mean scores and standard deviation for training and validation sets\n",
        "\n",
        "auc_table = np.empty((3,len(names),len(data_generators)))\n",
        "auc_table[0,:,:] = np.mean(AUC_train,axis = 1) # train means\n",
        "#f1_table[1,:,:] = np.std(f1_train,axis = 1) # train sd\n",
        "auc_table[1,:,:] = np.mean(AUC_val,axis = 1) # val means\n",
        "#f1_table[3,:] = np.std(f1_val,axis = 1) # val sd\n",
        "auc_table[2,:,:] = AUC_test[:,0] # test score\n",
        "\n",
        "auc_table = np.around(auc_table,decimals=2)\n",
        "\n",
        "print(\"Undersampling\")\n",
        "print(tabulate(auc_table[:,:,0],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"CTGAN\")\n",
        "print(tabulate(auc_table[:,:,1],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"Smote\")\n",
        "print(tabulate(auc_table[:,:,2],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"VAE\")\n",
        "print(tabulate(auc_table[:,:,3],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undersampling\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.74          0.73       0.77          0.68             1                1           0.92\n",
            "                 0.72          0.66       0.69          0.62             0.66             0.64        0.66\n",
            "                 0.74          0.77       0.75          0.8              0.61             0.7         0.78\n",
            "CTGAN\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.76          0.75       0.81          0.73             1                1           0.96\n",
            "                 0.74          0.73       0.75          0.73             0.82             0.86        0.83\n",
            "                 0.59          0.6        0.62          0.65             0.66             0.79        0.77\n",
            "Smote\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.75          0.73       0.77          0.68             1                1           0.93\n",
            "                 0.71          0.72       0.73          0.65             0.78             0.85        0.8\n",
            "                 0.78          0.77       0.8           0.55             0.74             0.76        0.82\n",
            "VAE\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.74          0.77       0.83          0.67             1                1           0.94\n",
            "                 0.74          0.76       0.78          0.66             0.81             0.84        0.83\n",
            "                 0.62          0.71       0.66          0.81             0.67             0.8         0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz4D19vlxeHB",
        "outputId": "c26f77ff-9e5c-4fb7-b2c7-ba1526b20ce9"
      },
      "source": [
        "# calculating f1 mean scores and standard deviation for training and validation sets\n",
        "\n",
        "f1_table = np.empty((3,len(names),len(data_generators)))\n",
        "f1_table[0,:,:] = np.mean(f1_train,axis = 1) # train means\n",
        "#f1_table[1,:,:] = np.std(f1_train,axis = 1) # train sd\n",
        "f1_table[1,:,:] = np.mean(f1_val,axis = 1) # val means\n",
        "#f1_table[3,:] = np.std(f1_val,axis = 1) # val sd\n",
        "f1_table[2,:,:] = f1_test[:,0] # test f1 score\n",
        "\n",
        "f1_table = np.around(f1_table,decimals=2)\n",
        "\n",
        "print(\"Undersampling\")\n",
        "print(tabulate(f1_table[:,:,0],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"CTGAN\")\n",
        "print(tabulate(f1_table[:,:,1],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"Smote\")\n",
        "print(tabulate(f1_table[:,:,2],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"VAE\")\n",
        "print(tabulate(f1_table[:,:,3],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undersampling\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.46          0.45       0.49          0.42             1                1           0.89\n",
            "                 0.45          0.39       0.42          0.35             0.43             0.42        0.43\n",
            "                 0.07          0.07       0.07          0.16             0.08             0.32        0.21\n",
            "CTGAN\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.64          0.63       0.72          0.6              1                1           0.96\n",
            "                 0.64          0.62       0.64          0.61             0.73             0.83        0.76\n",
            "                 0.06          0.06       0.06          0.07             0.09             0.3         0.19\n",
            "Smote\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.63          0.61       0.65          0.56             1                1           0.91\n",
            "                 0.57          0.58       0.59          0.51             0.67             0.8         0.7\n",
            "                 0.08          0.07       0.08          0.14             0.12             0.24        0.18\n",
            "VAE\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.64          0.66       0.75          0.56              1               1           0.93\n",
            "                 0.59          0.6        0.64          0.51              0.7             0.78        0.75\n",
            "                 0.06          0.08       0.09          0.1               0.1             0.38        0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8iscFYhhMYy",
        "outputId": "96652b71-81ae-419c-94e6-436c512d032c"
      },
      "source": [
        "# calculating accuracy mean scores and standard deviation for training and validation sets\n",
        "\n",
        "acc_table = np.empty((3,len(names),len(data_generators)))\n",
        "acc_table[0,:,:] = np.mean(acc_train,axis = 1) # train means\n",
        "#acc_table[1,:,:] = np.std(acc_train,axis = 1) # train sd\n",
        "acc_table[1,:,:] = np.mean(acc_val,axis = 1) # val means\n",
        "#acc_table[3,:] = np.std(acc_val,axis = 1) # val sd\n",
        "acc_table[2,:,:] = acc_test[:,0] # test acc score\n",
        "\n",
        "acc_table = np.around(acc_table,decimals=2)\n",
        "\n",
        "print(\"Undersampling\")\n",
        "print(tabulate(acc_table[:,:,0],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"CTGAN\")\n",
        "print(tabulate(acc_table[:,:,1],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"Smote\")\n",
        "print(tabulate(acc_table[:,:,2],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"VAE\")\n",
        "print(tabulate(acc_table[:,:,3],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undersampling\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.69          0.66       0.7           0.63             1                1           0.97\n",
            "                 0.68          0.62       0.67          0.61             0.8              0.85        0.83\n",
            "                 0.64          0.6        0.61          0.87             0.85             0.97        0.92\n",
            "CTGAN\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.77          0.77       0.83          0.79             1                1           0.98\n",
            "                 0.76          0.75       0.77          0.79             0.84             0.91        0.86\n",
            "                 0.76          0.78       0.77          0.77             0.84             0.95        0.91\n",
            "Smote\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.72          0.68       0.73          0.59             1                1           0.95\n",
            "                 0.68          0.65       0.67          0.56             0.8              0.89        0.83\n",
            "                 0.66          0.59       0.65          0.98             0.85             0.94        0.89\n",
            "VAE\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.73          0.74       0.83          0.69             1                1           0.96\n",
            "                 0.74          0.72       0.78          0.68             0.85             0.9         0.88\n",
            "                 0.76          0.73       0.85          0.73             0.86             0.96        0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK7avNEghmn5",
        "outputId": "7f8b383c-9106-4edf-d305-aefdcc22f846"
      },
      "source": [
        "# calculating recall mean scores and standard deviation for training and validation sets\n",
        "\n",
        "recall_table = np.empty((3,len(names),len(data_generators)))\n",
        "recall_table[0,:,:] = np.mean(recall_train,axis = 1) # train means\n",
        "#recall_table[1,:,:] = np.std(recall_train,axis = 1) # train sd\n",
        "recall_table[1,:,:] = np.mean(recall_val,axis = 1) # val means\n",
        "#recall_table[3,:] = np.std(recall_val,axis = 1) # val sd\n",
        "recall_table[2,:,:] = recall_test[:,0] # test recall score\n",
        "\n",
        "recall_table = np.around(recall_table,decimals=2)\n",
        "\n",
        "print(\"Undersampling\")\n",
        "print(tabulate(recall_table[:,:,0],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"CTGAN\")\n",
        "print(tabulate(recall_table[:,:,1],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"Smote\")\n",
        "print(tabulate(recall_table[:,:,2],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))\n",
        "print(\"VAE\")\n",
        "print(tabulate(recall_table[:,:,3],headers = (\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\"Perceptron\",\"Decision Tree\",\"Random Forest\", \"AdaBoost\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undersampling\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.81          0.85       0.88          0.76             1                1           0.85\n",
            "                 0.78          0.72       0.72          0.65             0.45             0.31        0.39\n",
            "                 0.84          0.95       0.89          0.74             0.37             0.42        0.63\n",
            "CTGAN\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.73          0.71       0.79          0.59             1                1           0.94\n",
            "                 0.7           0.67       0.69          0.59             0.75             0.75        0.74\n",
            "                 0.42          0.42       0.47          0.53             0.47             0.63        0.63\n",
            "Smote\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.82          0.87       0.87          0.87             1                1           0.89\n",
            "                 0.78          0.88       0.85          0.84             0.74             0.75        0.73\n",
            "                 0.89          0.95       0.95          0.11             0.63             0.58        0.74\n",
            "VAE\n",
            "  Logistic Regression    Linear SVM    RBF SVM    Perceptron    Decision Tree    Random Forest    AdaBoost\n",
            "---------------------  ------------  ---------  ------------  ---------------  ---------------  ----------\n",
            "                 0.77          0.84       0.82          0.62             1                1           0.9\n",
            "                 0.74          0.83       0.78          0.6              0.73             0.71        0.73\n",
            "                 0.47          0.68       0.47          0.89             0.47             0.63        0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E2bYnVie8Vm"
      },
      "source": [
        "H2O algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jKgQkKrQXXy"
      },
      "source": [
        "# gradient boosting model from H2O run with data synthesis methods\n",
        "# https://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/GBMBooklet.pdf & https://docs.h2o.ai/h2o/latest-stable/h2o-docs/training-models.html \n",
        "\n",
        "h2o.init()\n",
        "\n",
        "data_generators = [undersample, CTGAN, Smote_function, VAE_synthesise]\n",
        "\n",
        "h2o_performance = np.empty((6,len(data_generators)))\n",
        "\n",
        "i = 0\n",
        "for gen in data_generators:\n",
        "  # split between training and in-sample test set\n",
        "  X_train, Y_train, X_final_test, Y_final_test = gen(original_policies)\n",
        "\n",
        "  GBMdata_train = np.append(X_train,np.expand_dims(Y_train,axis=1),axis=1)\n",
        "  GBMdata_test = np.append(X_final_test,np.expand_dims(Y_final_test,axis=1),axis=1)\n",
        "\n",
        "  GBMdata_train = h2o.H2OFrame(GBMdata_train)\n",
        "  GBMdata_train[(claim_policies.shape[1]-1)] = GBMdata_train[(claim_policies.shape[1]-1)].asfactor()\n",
        "  GBMdata_test = h2o.H2OFrame(GBMdata_test)\n",
        "  GBMdata_test[(claim_policies.shape[1]-1)] = GBMdata_test[(claim_policies.shape[1]-1)].asfactor()\n",
        "\n",
        "  # training model\n",
        "  air_model = H2OGradientBoostingEstimator(nfolds = 5,distribution = 'bernoulli',sample_rate = .7, seed = 1234)\n",
        "  air_model.train(y = (claim_policies.shape[1]-1), training_frame = GBMdata_train)\n",
        "\n",
        "  # making predictions and storing performance metrics\n",
        "  pred_h2o = air_model.predict(GBMdata_test)\n",
        "  pred_h2o = pred_h2o.as_data_frame().to_numpy()\n",
        "\n",
        "  perf_train = air_model.model_performance(GBMdata_train)\n",
        "  h2o_performance[0,i] = perf_train.auc()\n",
        "  h2o_performance[1,i] = perf_train.F1()[0][1]\n",
        "\n",
        "  perf_val = air_model.model_performance(GBMdata_train,xval = True)\n",
        "  h2o_performance[2,i] = perf_val.auc()\n",
        "  h2o_performance[3,i] = perf_val.F1()[0][1]\n",
        "\n",
        "  perf_test = air_model.model_performance(GBMdata_test)\n",
        "  h2o_performance[4,i] = perf_test.auc()\n",
        "  h2o_performance[5,i] = perf_test.F1()[0][1]\n",
        "\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYe_6pfCCr_w",
        "outputId": "b567c194-0ae8-492d-f747-de55c85518c0"
      },
      "source": [
        "print(tabulate(h2o_performance,headers = (\"undersample\", \"CTGAN\", \"Smote_function\", \"VAE_synthesise\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  undersample     CTGAN    Smote_function    VAE_synthesise\n",
            "-------------  --------  ----------------  ----------------\n",
            "     0.998044  0.998791          0.999378          0.999538\n",
            "     0.951724  0.976898          0.986755          0.987179\n",
            "     0.998044  0.998791          0.999378          0.999538\n",
            "     0.951724  0.976898          0.986755          0.987179\n",
            "     0.89443   0.910786          0.920557          0.921029\n",
            "     0.327273  0.304348          0.333333          0.358209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwKS1cygfCja"
      },
      "source": [
        "Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG5uZ46jizMX"
      },
      "source": [
        "# neural network from PyTorch\n",
        "# https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(26, 10)\n",
        "        self.fc2 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SrRYN_okfUb"
      },
      "source": [
        "num_epochs = 500\n",
        "learning_rate = 0.01\n",
        "losstype = nn.CrossEntropyLoss()\n",
        "\n",
        "data_generators = [undersample, CTGAN, Smote_function,VAE_synthesise]\n",
        "\n",
        "nn_performance = np.empty((6,len(data_generators)))\n",
        "\n",
        "j = 0\n",
        "for gen in data_generators:\n",
        "  # split between training and in-sample test set\n",
        "  X_train, Y_train, X_final_test, Y_final_test = gen(original_policies)\n",
        "\n",
        "  X_train = torch.from_numpy(X_train).type(torch.float)\n",
        "  Y_train = torch.from_numpy(Y_train).type(torch.float)\n",
        "  X_final_test = torch.from_numpy(X_final_test).type(torch.float)\n",
        "  Y_final_test = torch.from_numpy(Y_final_test).type(torch.float)\n",
        "\n",
        "  n_splits = 5\n",
        "\n",
        "  # setting up performance metric tables\n",
        "  f1_train_net = np.zeros((n_splits))\n",
        "  f1_val_net = np.zeros((n_splits))\n",
        "  f1_test_net = np.zeros((n_splits))\n",
        "\n",
        "  ROC_train_net = np.zeros((n_splits))\n",
        "  ROC_val_net = np.zeros((n_splits))\n",
        "  ROC_test_net = np.zeros((n_splits))\n",
        "\n",
        "  accuracy_train_net = np.zeros((n_splits))\n",
        "  accuracy_val_net = np.zeros((n_splits))\n",
        "  accuracy_test_net = np.zeros((n_splits))\n",
        "\n",
        "  recall_train_net = np.zeros((n_splits))\n",
        "  recall_val_net = np.zeros((n_splits))\n",
        "  recall_test_net = np.zeros((n_splits))\n",
        "\n",
        "  # cross validation\n",
        "  rs = ShuffleSplit(n_splits=n_splits, random_state=0, test_size=0.2, train_size=None)\n",
        "  i = 0\n",
        "  for train_index, test_index in rs.split(X_train):\n",
        "    X_t = X_train[train_index]\n",
        "    Y_t = Y_train[train_index] \n",
        "    X_val = X_train[test_index]\n",
        "    Y_val = Y_train[test_index] \n",
        "\n",
        "    net = Net()\n",
        "    optimiser = torch.optim.Adam(net.parameters(),lr = learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      # back propagation\n",
        "      ypred = net(X_t)\n",
        "      _,prediction = torch.max(ypred,1)\n",
        "      loss = losstype(ypred,Y_t.long())\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # recording performance metrics\n",
        "      accuracy_train_net[i] = (prediction == Y_t).sum().item()/len(Y_t)\n",
        "      index = np.where(Y_t == 1)\n",
        "      prediction_dummy = prediction[index[0]]\n",
        "      Y_dummy = Y_t[index[0]]\n",
        "      recall_train_net[i] = (prediction_dummy == Y_dummy).sum().item()/sum(Y_t)\n",
        "      f1_train_net[i] = f1_score(Y_t, prediction)\n",
        "      ROC_train_net[i] = roc_auc_score(Y_t,prediction)\n",
        "\n",
        "      ypred_val = net(X_val)\n",
        "      _,prediction_val = torch.max(ypred_val,1)\n",
        "      accuracy_val_net[i] = (prediction_val == Y_val).sum().item()/len(Y_val)\n",
        "      index = np.where(Y_val == 1)\n",
        "      prediction_dummy = prediction_val[index[0]]\n",
        "      Y_dummy = Y_val[index[0]]\n",
        "      recall_val_net[i] = (prediction_dummy == Y_dummy).sum().item()/sum(Y_val)\n",
        "      f1_val_net[i] = f1_score(Y_val, prediction_val)\n",
        "      ROC_val_net[i] = roc_auc_score(Y_val, prediction_val)\n",
        "\n",
        "      ypred_test = net(X_final_test)\n",
        "      _,prediction_test = torch.max(ypred_test,1)\n",
        "      accuracy_test_net[i] = (prediction_test == Y_final_test).sum().item()/len(Y_final_test)\n",
        "      index = np.where(Y_final_test == 1)\n",
        "      prediction_dummy = prediction_test[index[0]]\n",
        "      Y_dummy = Y_final_test[index[0]]\n",
        "      recall_test_net[i] = (prediction_dummy == Y_dummy).sum().item()/sum(Y_final_test)\n",
        "      f1_test_net[i] = f1_score(Y_final_test, prediction_test)\n",
        "      ROC_test_net[i] = roc_auc_score(Y_final_test, prediction_test)\n",
        "    \n",
        "    i += 1\n",
        "  \n",
        "  nn_performance[0,j] = np.mean(ROC_train_net)\n",
        "  nn_performance[1,j] = np.mean(f1_train_net)\n",
        "  nn_performance[2,j] = np.mean(ROC_val_net)\n",
        "  nn_performance[3,j] = np.mean(f1_val_net)\n",
        "  nn_performance[4,j] = np.mean(ROC_test_net)\n",
        "  nn_performance[5,j] = np.mean(f1_test_net)\n",
        "\n",
        "  j += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_C9rhuvKhw4",
        "outputId": "5e5ed1bf-6889-4804-ec73-5a6071a9cbe5"
      },
      "source": [
        "print(tabulate(nn_performance,headers = (\"undersample\", \"CTGAN\", \"Smote_function\", \"VAE_synthesise\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  undersample     CTGAN    Smote_function    VAE_synthesise\n",
            "-------------  --------  ----------------  ----------------\n",
            "     0.696193  0.80553           0.868842          0.890851\n",
            "     0.550837  0.74451           0.817461          0.857946\n",
            "     0.659513  0.729236          0.783894          0.825207\n",
            "     0.465072  0.617824          0.676554          0.751331\n",
            "     0.649946  0.679198          0.682346          0.698338\n",
            "     0.192567  0.154771          0.108364          0.147884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDCvfDSLT7Yx"
      },
      "source": [
        "**Unsupervised Algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IUTfd67pZGU"
      },
      "source": [
        "Local Density Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aIOfmedUv96"
      },
      "source": [
        "# Calculating Euclidean distance between points and gaussian kernel matrix\n",
        "\n",
        "X_train = original_policies[:,:-1]\n",
        "Y_train = original_policies[:,-1]\n",
        "\n",
        "cont_data = original_policies[:,6:]\n",
        "EucDistance = np.zeros((cont_data.shape[0],cont_data.shape[0]))\n",
        "\n",
        "i = 0\n",
        "while i < cont_data.shape[0]:\n",
        "    temp = cont_data[i,:] - cont_data\n",
        "    dist = (np.sum((temp*temp),axis=1))**0.5\n",
        "    EucDistance[i,:] = dist\n",
        "    i += 1\n",
        "Kernel = np.exp(-(EucDistance**2))\n",
        "\n",
        "# knn is nearest neighbours of each policy, rnn is polcies that have a policy within their k nearest neighbours\n",
        "k = 20\n",
        "knn = np.zeros((cont_data.shape[0],k))\n",
        "rnn = np.zeros((cont_data.shape[0],cont_data.shape[0]))\n",
        "vertind = np.zeros((cont_data.shape[0])).astype(int)\n",
        "\n",
        "i = 0\n",
        "while i < cont_data.shape[0]:\n",
        "  idx = (EucDistance[i,:]).argsort()[:k]\n",
        "  knn[i,:] = idx # need to remove the point itself from nn, maybe extend to 11 point including?\n",
        "  rnn[idx,vertind[idx]] = i\n",
        "  vertind[idx] += 1\n",
        "  i += 1\n",
        "rnn = rnn[:,0:np.max(vertind)+1]\n",
        "\n",
        "# snn is polcies that are in each others k nearest neighbours\n",
        "snn = np.zeros((cont_data.shape[0],cont_data.shape[0]))\n",
        "vi = np.zeros((cont_data.shape[0])).astype(int)\n",
        "\n",
        "i = 0\n",
        "while i < cont_data.shape[0]:\n",
        "  j = 0\n",
        "  while j < k:\n",
        "    neighbour = int(knn[i,j])\n",
        "    if i in knn[neighbour,:]:\n",
        "      snn[i,vi[i]] = neighbour\n",
        "      vi[i] += 1\n",
        "    j += 1\n",
        "  i += 1\n",
        "snn = snn[:,0:np.max(vi)+1]\n",
        "pXp = np.zeros((cont_data.shape[0]))\n",
        "\n",
        "i = 0\n",
        "while i < cont_data.shape[0]:\n",
        "  nn = np.concatenate((knn[i,:],rnn[i,0:vertind[i]],snn[i,0:vi[i]])).astype(int)\n",
        "  pxp = 0\n",
        "  for j in nn:\n",
        "    pxp += Kernel[i,j]/len(nn)\n",
        "  pXp[i] = pxp\n",
        "  i += 1\n",
        "\n",
        "RDOS = np.zeros((cont_data.shape[0]))\n",
        "\n",
        "i = 0\n",
        "while i < cont_data.shape[0]:\n",
        "  nn = np.concatenate((knn[i,:],rnn[i,0:vertind[i]],snn[i,0:vi[i]])).astype(int)\n",
        "  rdos = 0\n",
        "  for j in nn:\n",
        "    rdos += pXp[j]/(len(nn)*pXp[i])\n",
        "  RDOS[i] = rdos\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAhjmCW1wsLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f303c811-1f9b-496d-d876-d1a0c9011833"
      },
      "source": [
        "# performance metrics for local density algorithm\n",
        "\n",
        "probs_kernel = classification(RDOS,np.percentile(RDOS,90))\n",
        "\n",
        "accuracy_density = (probs_kernel == Y_train).sum().item()/len(Y_train)\n",
        "index = np.where(Y_train == 1)\n",
        "prediction_dummy = probs_kernel[index[0]]\n",
        "Y_dummy = Y_train[index[0]]\n",
        "recall_density = (prediction_dummy == Y_dummy).sum().item()/sum(Y_train)\n",
        "f1_density = f1_score(Y_train, probs_kernel)\n",
        "auc_density = roc_auc_score(Y_train, probs_kernel)\n",
        "\n",
        "print(\"F1 score train\", f1_density)\n",
        "print(\"AUC train\", auc_density)\n",
        "print(\"accuracy score train\", accuracy_density)\n",
        "print(\"recall score train\", recall_density)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score train 0.08472012102874432\n",
            "AUC train 0.6005780148206971\n",
            "accuracy score train 0.8932415740250573\n",
            "recall score train 0.2978723404255319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YnHwvztpeWx"
      },
      "source": [
        "ODMAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDlyVEU5AgcV"
      },
      "source": [
        "# ODMAD algorithm \n",
        "# foreach point xi ( i = 1..n) begin Add the categorical values of xi , their frequencies, & their means to A;\n",
        "\n",
        "from itertools import combinations\n",
        "import collections\n",
        "\n",
        "X_train = original_policies[:,:-1]\n",
        "Y_train = original_policies[:,-1]\n",
        "\n",
        "cat_data = X_train[:,0:6]\n",
        "con_data = X_train[:,6:] \n",
        "cat_comb = {} # dictionary of different categorical variable combinations in the data set mapped to their frequency\n",
        "max_len = 5 # maximum length of each variable combination\n",
        "num_attributes = cat_data.shape[1] # number of categorical attributes\n",
        "minsup = 200 # value is infrequent if it appears fewer than minsup times in data\n",
        "A = np.zeros((cat_data.shape[0],num_attributes,3)) # storing frequency and mean for each individual catagorical variable value\n",
        "\n",
        "# storing frequency and mean for each individual catagorical variable value\n",
        "i = 0\n",
        "while i < cat_data.shape[0]:\n",
        "  A[i,:,0] = cat_data[i,:]\n",
        "  j = 0\n",
        "  while j < num_attributes:\n",
        "    freqs = collections.Counter(cat_data[:,j]) # dictionary of frequency of each data value for attribute j\n",
        "    freq = freqs[A[i,j,0]] # frequency of data value in data set\n",
        "    mean = np.mean(cat_data[:,j]) # mean of all data values in data set\n",
        "    A[i,j,1] = freq\n",
        "    A[i,j,2] = mean\n",
        "    j += 1\n",
        "\n",
        "  # counting number of combinations of variables in data\n",
        "  l = 2\n",
        "  while l <= max_len:\n",
        "    for comb in combinations(A[i,:,0],l): # number of different combinations of length l\n",
        "      if comb not in cat_comb:\n",
        "        cat_comb[comb] = 1\n",
        "      else:\n",
        "        cat_comb[comb] = cat_comb[comb] + 1\n",
        "    l += 1\n",
        "  i += 1\n",
        "\n",
        "# updating dictionary to remove variable value combination with a frequency above minsup\n",
        "keys = []\n",
        "for key in cat_comb:\n",
        "  if cat_comb[key] >= minsup: # value is infrequent if it appears less than minsup times in data\n",
        "    keys.append(key)\n",
        "for key in keys:\n",
        "  cat_comb.pop(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHlf7hP0Dook"
      },
      "source": [
        "# ODMAD algorithm \n",
        "# calculating categorical score for each policy\n",
        "score1 = np.zeros((cat_data.shape[0])) # to store score1 values for each data point\n",
        "score2 = np.zeros((cat_data.shape[0]))\n",
        "m = 0\n",
        "n = 500 # number of points in calculation of average scores\n",
        "window_score1 = np.zeros((n))\n",
        "window_score2 = np.zeros((n))\n",
        "delta_c = 10\n",
        "delta_q = 0.2\n",
        "cos_val = np.zeros((cat_data.shape[0],num_attributes)) # to store cos angles between vectors\n",
        "low_sup = 100 # user-entered frequency threshold to indicate what values we consider ‘highly infrequent'. Exclude these points from the mean calculation\n",
        "upper_sup = 5000 # applying an upper bound we limit the amount of data points to which we assign a score in the continuous domain.\n",
        "outlier = np.zeros((cat_data.shape[0]))\n",
        "\n",
        "i = 0\n",
        "while i < cat_data.shape[0]:\n",
        "  v1 = con_data[i,:] # vector of continuous variables of data point i\n",
        "  j = 0\n",
        "  while j < num_attributes:\n",
        "    if A[i,j,1] < minsup: # if frequency of categorical variable is less than minsup\n",
        "      score1[i] += 1/A[i,j,1] # adding 1 divided by frequency of categorical variable\n",
        "    if low_sup < A[i,j,1] <= upper_sup:\n",
        "      ind = np.where(A[:,j,1] == A[i,j,1]) # all data points that share the same value of the categorical variable\n",
        "      # ind = np.delete(ind, np.where(ind == i)) # remove data point i from the indices as shouldn't be compared to itself\n",
        "      av_vector = np.zeros((con_data.shape[1])) # mean vector of all vectors in set\n",
        "      for p in ind[0]:\n",
        "        v2 = con_data[p,:] # vector of continuous variables of data point p\n",
        "        av_vector += v2/len(ind) # updating average vector with latest data point\n",
        "      cos_val[i,j] = v1 @ av_vector / (np.linalg.norm(v1,ord = 2) * np.linalg.norm(av_vector, ord = 2)) # needs to update mean vector excluding points below low_sup\n",
        "    j += 1\n",
        "  score2[i] = np.sum(cos_val[i]) / num_attributes # sum across all categorical values for each data point\n",
        "  l = 2\n",
        "  while l <= max_len:\n",
        "    for comb in combinations(A[i,:,0],l):\n",
        "      try:\n",
        "        score1[i] += 1 / (cat_comb[comb] * l)\n",
        "      except:\n",
        "        score1[i] += 0\n",
        "    l += 1\n",
        "  if score1[i] > delta_c * np.mean(window_score1[0:min(n,m+1)]):\n",
        "    outlier[i] = 1\n",
        "  elif score2[i] < delta_q * np.mean(window_score2[0:min(n,m+1)]):\n",
        "    outlier[i] = 1\n",
        "  else:\n",
        "    pos = m % n\n",
        "    window_score1[pos] = score1[i]\n",
        "    window_score2[pos] = score2[i]\n",
        "    m += 1\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAlCsnIXM2n1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a905684-ceec-4878-a08e-a9fd40f50482"
      },
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve\n",
        "# ROC curve for my algorithms\n",
        "\n",
        "accuracy_ODMAD = (outlier == Y_train).sum().item()/len(Y_train)\n",
        "index = np.where(Y_train == 1)\n",
        "prediction_dummy = outlier[index[0]]\n",
        "Y_dummy = Y_train[index[0]]\n",
        "recall_ODMAD = (prediction_dummy == Y_dummy).sum().item()/sum(Y_train)\n",
        "f1_ODMAD = f1_score(Y_train, outlier)\n",
        "ROC_ODMAD = roc_auc_score(Y_train, outlier)\n",
        "\n",
        "print(\"F1 score train\", f1_ODMAD)\n",
        "print(\"AUC train\", ROC_ODMAD)\n",
        "print(\"accuracy score train\", accuracy_ODMAD)\n",
        "print(\"recall score train\", recall_ODMAD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score train 0.03494721514379323\n",
            "AUC train 0.5216030175886015\n",
            "accuracy score train 0.5322039880007058\n",
            "recall score train 0.5106382978723404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI9Da5z9YPmI"
      },
      "source": [
        "**Parameter Testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBYTgAUNp1R5"
      },
      "source": [
        "H2O GBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Gf2RzthHxa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07c7a68b-8110-4c62-af5b-d17ee655f966"
      },
      "source": [
        "h2o.init()\n",
        "\n",
        "data_generators = [VAE_synthesise]\n",
        "\n",
        "learning_rate = [0.1]\n",
        "number_trees = [200]\n",
        "maximum_depth = [10]\n",
        "minimum_rows = [5]\n",
        "\n",
        "for gen in data_generators:\n",
        "\n",
        "  # split into training and in-sample test sets\n",
        "  X_train, Y_train, X_final_test, Y_final_test = gen(original_policies) \n",
        "\n",
        "  GBMdata_train = np.append(X_train,np.expand_dims(Y_train,axis=1),axis=1)\n",
        "  GBMdata_test = np.append(X_final_test,np.expand_dims(Y_final_test,axis=1),axis=1)\n",
        "\n",
        "  GBMdata_train = h2o.H2OFrame(GBMdata_train)\n",
        "  GBMdata_train[(claim_policies.shape[1]-1)] = GBMdata_train[(claim_policies.shape[1]-1)].asfactor()\n",
        "  GBMdata_test = h2o.H2OFrame(GBMdata_test)\n",
        "  GBMdata_test[(claim_policies.shape[1]-1)] = GBMdata_test[(claim_policies.shape[1]-1)].asfactor()\n",
        "\n",
        "  for lr in learning_rate:\n",
        "    for nt in number_trees:\n",
        "      for md in maximum_depth:\n",
        "        for mr in minimum_rows:\n",
        "\n",
        "          # define model and train\n",
        "          air_model =  H2OGradientBoostingEstimator(nfolds = 5, distribution = 'bernoulli', sample_rate = .7, ntrees = nt, max_depth = md, min_rows = mr, learn_rate = lr, seed = 1234)\n",
        "          air_model.train(y = (claim_policies.shape[1]-1), training_frame = GBMdata_train)\n",
        "\n",
        "          # predictions and performance on test set\n",
        "          pred_h2o = air_model.predict(GBMdata_test)\n",
        "          perf_test = air_model.model_performance(GBMdata_test)\n",
        "\n",
        "          print(\"learning rate\", lr, \"number trees\", nt, \"maximum depth\", md, \"minimum rows\", mr, \"AUC\", perf_test.auc() )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>1 hour 50 mins</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.32.1.7</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>6 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_9ammu1</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>2.542 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>H2O_API_Extensions:</td>\n",
              "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.7.11 final</td></tr></table></div>"
            ],
            "text/plain": [
              "--------------------------  ------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         1 hour 50 mins\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.32.1.7\n",
              "H2O_cluster_version_age:    6 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_9ammu1\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    2.542 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
              "Python_version:             3.7.11 final\n",
              "--------------------------  ------------------------------------------------------------------"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750\n",
            "4/4 [==============================] - 1s 6ms/step - loss: 4.3302\n",
            "Epoch 2/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.2725\n",
            "Epoch 3/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.2085\n",
            "Epoch 4/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.1515\n",
            "Epoch 5/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.1087\n",
            "Epoch 6/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.0677\n",
            "Epoch 7/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.0290\n",
            "Epoch 8/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.9764\n",
            "Epoch 9/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.9443\n",
            "Epoch 10/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.8970\n",
            "Epoch 11/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.8620\n",
            "Epoch 12/750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.8220\n",
            "Epoch 13/750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.7594\n",
            "Epoch 14/750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.6947\n",
            "Epoch 15/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.6410\n",
            "Epoch 16/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.5730\n",
            "Epoch 17/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.5009\n",
            "Epoch 18/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.4176\n",
            "Epoch 19/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.3429\n",
            "Epoch 20/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.2452\n",
            "Epoch 21/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.1352\n",
            "Epoch 22/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.0523\n",
            "Epoch 23/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.9554\n",
            "Epoch 24/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.8476\n",
            "Epoch 25/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.7621\n",
            "Epoch 26/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.6475\n",
            "Epoch 27/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.5597\n",
            "Epoch 28/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.4803\n",
            "Epoch 29/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3668\n",
            "Epoch 30/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2687\n",
            "Epoch 31/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.1817\n",
            "Epoch 32/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.1143\n",
            "Epoch 33/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.0148\n",
            "Epoch 34/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.9496\n",
            "Epoch 35/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.8479\n",
            "Epoch 36/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.8036\n",
            "Epoch 37/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.7462\n",
            "Epoch 38/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.6588\n",
            "Epoch 39/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.6251\n",
            "Epoch 40/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.5640\n",
            "Epoch 41/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.5320\n",
            "Epoch 42/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.4631\n",
            "Epoch 43/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.4145\n",
            "Epoch 44/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.3727\n",
            "Epoch 45/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.3552\n",
            "Epoch 46/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.3188\n",
            "Epoch 47/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.2635\n",
            "Epoch 48/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.2309\n",
            "Epoch 49/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.2079\n",
            "Epoch 50/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1940\n",
            "Epoch 51/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1598\n",
            "Epoch 52/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1146\n",
            "Epoch 53/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1085\n",
            "Epoch 54/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0672\n",
            "Epoch 55/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0614\n",
            "Epoch 56/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0076\n",
            "Epoch 57/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.0034\n",
            "Epoch 58/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.9827\n",
            "Epoch 59/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.9583\n",
            "Epoch 60/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9411\n",
            "Epoch 61/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9380\n",
            "Epoch 62/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.8996\n",
            "Epoch 63/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8758\n",
            "Epoch 64/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8698\n",
            "Epoch 65/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.8566\n",
            "Epoch 66/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.8310\n",
            "Epoch 67/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.8115\n",
            "Epoch 68/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.8069\n",
            "Epoch 69/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7845\n",
            "Epoch 70/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7732\n",
            "Epoch 71/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7798\n",
            "Epoch 72/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7767\n",
            "Epoch 73/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7548\n",
            "Epoch 74/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7436\n",
            "Epoch 75/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7327\n",
            "Epoch 76/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 77/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7073\n",
            "Epoch 78/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7121\n",
            "Epoch 79/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7064\n",
            "Epoch 80/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6894\n",
            "Epoch 81/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6775\n",
            "Epoch 82/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6774\n",
            "Epoch 83/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6532\n",
            "Epoch 84/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6459\n",
            "Epoch 85/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6559\n",
            "Epoch 86/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6430\n",
            "Epoch 87/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6366\n",
            "Epoch 88/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6414\n",
            "Epoch 89/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6388\n",
            "Epoch 90/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6221\n",
            "Epoch 91/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6223\n",
            "Epoch 92/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6305\n",
            "Epoch 93/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5990\n",
            "Epoch 94/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5963\n",
            "Epoch 95/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5870\n",
            "Epoch 96/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5935\n",
            "Epoch 97/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5887\n",
            "Epoch 98/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5769\n",
            "Epoch 99/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5873\n",
            "Epoch 100/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5736\n",
            "Epoch 101/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5755\n",
            "Epoch 102/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5604\n",
            "Epoch 103/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5534\n",
            "Epoch 104/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5571\n",
            "Epoch 105/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5558\n",
            "Epoch 106/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5492\n",
            "Epoch 107/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5533\n",
            "Epoch 108/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5512\n",
            "Epoch 109/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5363\n",
            "Epoch 110/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5526\n",
            "Epoch 111/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5287\n",
            "Epoch 112/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5421\n",
            "Epoch 113/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5258\n",
            "Epoch 114/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5215\n",
            "Epoch 115/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5155\n",
            "Epoch 116/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5245\n",
            "Epoch 117/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5188\n",
            "Epoch 118/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5241\n",
            "Epoch 119/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5128\n",
            "Epoch 120/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5132\n",
            "Epoch 121/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5076\n",
            "Epoch 122/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5017\n",
            "Epoch 123/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5035\n",
            "Epoch 124/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4982\n",
            "Epoch 125/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5036\n",
            "Epoch 126/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4926\n",
            "Epoch 127/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4909\n",
            "Epoch 128/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4879\n",
            "Epoch 129/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4981\n",
            "Epoch 130/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4898\n",
            "Epoch 131/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4867\n",
            "Epoch 132/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4803\n",
            "Epoch 133/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4802\n",
            "Epoch 134/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4761\n",
            "Epoch 135/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4753\n",
            "Epoch 136/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4848\n",
            "Epoch 137/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4702\n",
            "Epoch 138/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4770\n",
            "Epoch 139/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4703\n",
            "Epoch 140/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4600\n",
            "Epoch 141/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4610\n",
            "Epoch 142/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4764\n",
            "Epoch 143/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4712\n",
            "Epoch 144/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4632\n",
            "Epoch 145/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4563\n",
            "Epoch 146/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4543\n",
            "Epoch 147/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4613\n",
            "Epoch 148/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4674\n",
            "Epoch 149/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4494\n",
            "Epoch 150/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4622\n",
            "Epoch 151/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4475\n",
            "Epoch 152/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4504\n",
            "Epoch 153/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4540\n",
            "Epoch 154/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4635\n",
            "Epoch 155/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4529\n",
            "Epoch 156/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4412\n",
            "Epoch 157/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4388\n",
            "Epoch 158/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4365\n",
            "Epoch 159/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4530\n",
            "Epoch 160/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4408\n",
            "Epoch 161/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4405\n",
            "Epoch 162/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4439\n",
            "Epoch 163/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4446\n",
            "Epoch 164/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4303\n",
            "Epoch 165/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4398\n",
            "Epoch 166/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4301\n",
            "Epoch 167/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4244\n",
            "Epoch 168/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4422\n",
            "Epoch 169/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4323\n",
            "Epoch 170/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4407\n",
            "Epoch 171/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4296\n",
            "Epoch 172/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4275\n",
            "Epoch 173/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4276\n",
            "Epoch 174/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4228\n",
            "Epoch 175/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4274\n",
            "Epoch 176/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4230\n",
            "Epoch 177/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4261\n",
            "Epoch 178/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4212\n",
            "Epoch 179/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4255\n",
            "Epoch 180/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4236\n",
            "Epoch 181/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4151\n",
            "Epoch 182/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4205\n",
            "Epoch 183/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4092\n",
            "Epoch 184/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4208\n",
            "Epoch 185/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4133\n",
            "Epoch 186/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4188\n",
            "Epoch 187/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4099\n",
            "Epoch 188/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4289\n",
            "Epoch 189/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4218\n",
            "Epoch 190/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4126\n",
            "Epoch 191/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4123\n",
            "Epoch 192/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4045\n",
            "Epoch 193/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4095\n",
            "Epoch 194/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4188\n",
            "Epoch 195/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4106\n",
            "Epoch 196/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4080\n",
            "Epoch 197/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4097\n",
            "Epoch 198/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4085\n",
            "Epoch 199/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3957\n",
            "Epoch 200/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4020\n",
            "Epoch 201/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4044\n",
            "Epoch 202/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4054\n",
            "Epoch 203/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3965\n",
            "Epoch 204/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4003\n",
            "Epoch 205/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3956\n",
            "Epoch 206/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3912\n",
            "Epoch 207/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3964\n",
            "Epoch 208/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4010\n",
            "Epoch 209/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4020\n",
            "Epoch 210/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3973\n",
            "Epoch 211/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4070\n",
            "Epoch 212/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4078\n",
            "Epoch 213/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3931\n",
            "Epoch 214/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3872\n",
            "Epoch 215/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3958\n",
            "Epoch 216/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3858\n",
            "Epoch 217/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3942\n",
            "Epoch 218/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3932\n",
            "Epoch 219/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3955\n",
            "Epoch 220/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3936\n",
            "Epoch 221/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3915\n",
            "Epoch 222/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3934\n",
            "Epoch 223/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4000\n",
            "Epoch 224/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3900\n",
            "Epoch 225/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3765\n",
            "Epoch 226/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3954\n",
            "Epoch 227/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3838\n",
            "Epoch 228/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3929\n",
            "Epoch 229/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3863\n",
            "Epoch 230/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3869\n",
            "Epoch 231/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3798\n",
            "Epoch 232/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3870\n",
            "Epoch 233/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3920\n",
            "Epoch 234/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3881\n",
            "Epoch 235/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3849\n",
            "Epoch 236/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3833\n",
            "Epoch 237/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3806\n",
            "Epoch 238/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3834\n",
            "Epoch 239/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3806\n",
            "Epoch 240/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3883\n",
            "Epoch 241/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3805\n",
            "Epoch 242/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3856\n",
            "Epoch 243/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3910\n",
            "Epoch 244/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3818\n",
            "Epoch 245/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3732\n",
            "Epoch 246/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3751\n",
            "Epoch 247/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3818\n",
            "Epoch 248/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3697\n",
            "Epoch 249/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3776\n",
            "Epoch 250/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3759\n",
            "Epoch 251/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3796\n",
            "Epoch 252/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3741\n",
            "Epoch 253/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3680\n",
            "Epoch 254/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3773\n",
            "Epoch 255/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3734\n",
            "Epoch 256/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3724\n",
            "Epoch 257/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3741\n",
            "Epoch 258/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3682\n",
            "Epoch 259/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3739\n",
            "Epoch 260/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3670\n",
            "Epoch 261/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3682\n",
            "Epoch 262/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3791\n",
            "Epoch 263/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3750\n",
            "Epoch 264/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3688\n",
            "Epoch 265/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3642\n",
            "Epoch 266/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3702\n",
            "Epoch 267/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3633\n",
            "Epoch 268/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3715\n",
            "Epoch 269/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3723\n",
            "Epoch 270/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3608\n",
            "Epoch 271/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3697\n",
            "Epoch 272/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3592\n",
            "Epoch 273/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3648\n",
            "Epoch 274/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3650\n",
            "Epoch 275/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3678\n",
            "Epoch 276/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3583\n",
            "Epoch 277/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3775\n",
            "Epoch 278/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3600\n",
            "Epoch 279/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3637\n",
            "Epoch 280/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3656\n",
            "Epoch 281/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3556\n",
            "Epoch 282/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3696\n",
            "Epoch 283/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3540\n",
            "Epoch 284/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3598\n",
            "Epoch 285/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3532\n",
            "Epoch 286/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3645\n",
            "Epoch 287/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3567\n",
            "Epoch 288/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3464\n",
            "Epoch 289/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3536\n",
            "Epoch 290/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3495\n",
            "Epoch 291/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3599\n",
            "Epoch 292/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3525\n",
            "Epoch 293/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3576\n",
            "Epoch 294/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3514\n",
            "Epoch 295/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3588\n",
            "Epoch 296/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3524\n",
            "Epoch 297/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3509\n",
            "Epoch 298/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3446\n",
            "Epoch 299/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3425\n",
            "Epoch 300/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3465\n",
            "Epoch 301/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3543\n",
            "Epoch 302/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3516\n",
            "Epoch 303/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3464\n",
            "Epoch 304/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3481\n",
            "Epoch 305/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3434\n",
            "Epoch 306/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3410\n",
            "Epoch 307/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3532\n",
            "Epoch 308/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3400\n",
            "Epoch 309/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3409\n",
            "Epoch 310/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3497\n",
            "Epoch 311/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3429\n",
            "Epoch 312/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3465\n",
            "Epoch 313/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3362\n",
            "Epoch 314/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3432\n",
            "Epoch 315/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3422\n",
            "Epoch 316/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3321\n",
            "Epoch 317/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3353\n",
            "Epoch 318/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3409\n",
            "Epoch 319/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3371\n",
            "Epoch 320/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3436\n",
            "Epoch 321/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3405\n",
            "Epoch 322/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3403\n",
            "Epoch 323/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3416\n",
            "Epoch 324/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3400\n",
            "Epoch 325/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3357\n",
            "Epoch 326/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3398\n",
            "Epoch 327/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3361\n",
            "Epoch 328/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3362\n",
            "Epoch 329/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3432\n",
            "Epoch 330/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3361\n",
            "Epoch 331/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3290\n",
            "Epoch 332/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3319\n",
            "Epoch 333/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3350\n",
            "Epoch 334/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3408\n",
            "Epoch 335/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3326\n",
            "Epoch 336/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3333\n",
            "Epoch 337/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3351\n",
            "Epoch 338/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3288\n",
            "Epoch 339/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3365\n",
            "Epoch 340/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3378\n",
            "Epoch 341/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3287\n",
            "Epoch 342/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3436\n",
            "Epoch 343/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3248\n",
            "Epoch 344/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3290\n",
            "Epoch 345/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3287\n",
            "Epoch 346/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3404\n",
            "Epoch 347/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3356\n",
            "Epoch 348/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3313\n",
            "Epoch 349/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3221\n",
            "Epoch 350/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3281\n",
            "Epoch 351/750\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3349\n",
            "Epoch 352/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3273\n",
            "Epoch 353/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3263\n",
            "Epoch 354/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3300\n",
            "Epoch 355/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3265\n",
            "Epoch 356/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3277\n",
            "Epoch 357/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3250\n",
            "Epoch 358/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3280\n",
            "Epoch 359/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3290\n",
            "Epoch 360/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3298\n",
            "Epoch 361/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3231\n",
            "Epoch 362/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3219\n",
            "Epoch 363/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3234\n",
            "Epoch 364/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3169\n",
            "Epoch 365/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3245\n",
            "Epoch 366/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3218\n",
            "Epoch 367/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3206\n",
            "Epoch 368/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3255\n",
            "Epoch 369/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3304\n",
            "Epoch 370/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3172\n",
            "Epoch 371/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3239\n",
            "Epoch 372/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3125\n",
            "Epoch 373/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3172\n",
            "Epoch 374/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3185\n",
            "Epoch 375/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3216\n",
            "Epoch 376/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3178\n",
            "Epoch 377/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3166\n",
            "Epoch 378/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3105\n",
            "Epoch 379/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3247\n",
            "Epoch 380/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3099\n",
            "Epoch 381/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3220\n",
            "Epoch 382/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3210\n",
            "Epoch 383/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3169\n",
            "Epoch 384/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3170\n",
            "Epoch 385/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3151\n",
            "Epoch 386/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3226\n",
            "Epoch 387/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3134\n",
            "Epoch 388/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3099\n",
            "Epoch 389/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3252\n",
            "Epoch 390/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3129\n",
            "Epoch 391/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3122\n",
            "Epoch 392/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3124\n",
            "Epoch 393/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3158\n",
            "Epoch 394/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3185\n",
            "Epoch 395/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3067\n",
            "Epoch 396/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3135\n",
            "Epoch 397/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3132\n",
            "Epoch 398/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3157\n",
            "Epoch 399/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3157\n",
            "Epoch 400/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3121\n",
            "Epoch 401/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3240\n",
            "Epoch 402/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3206\n",
            "Epoch 403/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3177\n",
            "Epoch 404/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3126\n",
            "Epoch 405/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3088\n",
            "Epoch 406/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3195\n",
            "Epoch 407/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3155\n",
            "Epoch 408/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3083\n",
            "Epoch 409/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3074\n",
            "Epoch 410/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3158\n",
            "Epoch 411/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3057\n",
            "Epoch 412/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3038\n",
            "Epoch 413/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3089\n",
            "Epoch 414/750\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3137\n",
            "Epoch 415/750\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3050\n",
            "Epoch 416/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3181\n",
            "Epoch 417/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3050\n",
            "Epoch 418/750\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3076\n",
            "Epoch 419/750\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3101\n",
            "Epoch 420/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3078\n",
            "Epoch 421/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3060\n",
            "Epoch 422/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3049\n",
            "Epoch 423/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3093\n",
            "Epoch 424/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3093\n",
            "Epoch 425/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3110\n",
            "Epoch 426/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3124\n",
            "Epoch 427/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3113\n",
            "Epoch 428/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3159\n",
            "Epoch 429/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3058\n",
            "Epoch 430/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3068\n",
            "Epoch 431/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3118\n",
            "Epoch 432/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3146\n",
            "Epoch 433/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3114\n",
            "Epoch 434/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3115\n",
            "Epoch 435/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3043\n",
            "Epoch 436/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3155\n",
            "Epoch 437/750\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3093\n",
            "Epoch 438/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3066\n",
            "Epoch 439/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3148\n",
            "Epoch 440/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3007\n",
            "Epoch 441/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3101\n",
            "Epoch 442/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3123\n",
            "Epoch 443/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3035\n",
            "Epoch 444/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3095\n",
            "Epoch 445/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3094\n",
            "Epoch 446/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3039\n",
            "Epoch 447/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3025\n",
            "Epoch 448/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3090\n",
            "Epoch 449/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3082\n",
            "Epoch 450/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3021\n",
            "Epoch 451/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3035\n",
            "Epoch 452/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3026\n",
            "Epoch 453/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3068\n",
            "Epoch 454/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3183\n",
            "Epoch 455/750\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3013\n",
            "Epoch 456/750\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3045\n",
            "Epoch 457/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3021\n",
            "Epoch 458/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3083\n",
            "Epoch 459/750\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3063\n",
            "Epoch 460/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3114\n",
            "Epoch 461/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3107\n",
            "Epoch 462/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3027\n",
            "Epoch 463/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3057\n",
            "Epoch 464/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3011\n",
            "Epoch 465/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3007\n",
            "Epoch 466/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3030\n",
            "Epoch 467/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2942\n",
            "Epoch 468/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3039\n",
            "Epoch 469/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3101\n",
            "Epoch 470/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3018\n",
            "Epoch 471/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3031\n",
            "Epoch 472/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2982\n",
            "Epoch 473/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2994\n",
            "Epoch 474/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3059\n",
            "Epoch 475/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2970\n",
            "Epoch 476/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2975\n",
            "Epoch 477/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3048\n",
            "Epoch 478/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3051\n",
            "Epoch 479/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2975\n",
            "Epoch 480/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2996\n",
            "Epoch 481/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3057\n",
            "Epoch 482/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3103\n",
            "Epoch 483/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2946\n",
            "Epoch 484/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3029\n",
            "Epoch 485/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3054\n",
            "Epoch 486/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2999\n",
            "Epoch 487/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3023\n",
            "Epoch 488/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3070\n",
            "Epoch 489/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3000\n",
            "Epoch 490/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2914\n",
            "Epoch 491/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3082\n",
            "Epoch 492/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3066\n",
            "Epoch 493/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2992\n",
            "Epoch 494/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3057\n",
            "Epoch 495/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3050\n",
            "Epoch 496/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2959\n",
            "Epoch 497/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2982\n",
            "Epoch 498/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3045\n",
            "Epoch 499/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3024\n",
            "Epoch 500/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2953\n",
            "Epoch 501/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2934\n",
            "Epoch 502/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2946\n",
            "Epoch 503/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2998\n",
            "Epoch 504/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3030\n",
            "Epoch 505/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2941\n",
            "Epoch 506/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3110\n",
            "Epoch 507/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3001\n",
            "Epoch 508/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2975\n",
            "Epoch 509/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2957\n",
            "Epoch 510/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3036\n",
            "Epoch 511/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2895\n",
            "Epoch 512/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3009\n",
            "Epoch 513/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2970\n",
            "Epoch 514/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2939\n",
            "Epoch 515/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2972\n",
            "Epoch 516/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2994\n",
            "Epoch 517/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3053\n",
            "Epoch 518/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2983\n",
            "Epoch 519/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3066\n",
            "Epoch 520/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3069\n",
            "Epoch 521/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2943\n",
            "Epoch 522/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3035\n",
            "Epoch 523/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2927\n",
            "Epoch 524/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3046\n",
            "Epoch 525/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3000\n",
            "Epoch 526/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2945\n",
            "Epoch 527/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2978\n",
            "Epoch 528/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2973\n",
            "Epoch 529/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3001\n",
            "Epoch 530/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3022\n",
            "Epoch 531/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2932\n",
            "Epoch 532/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2958\n",
            "Epoch 533/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2929\n",
            "Epoch 534/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3011\n",
            "Epoch 535/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2881\n",
            "Epoch 536/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3017\n",
            "Epoch 537/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2961\n",
            "Epoch 538/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2921\n",
            "Epoch 539/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2948\n",
            "Epoch 540/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3006\n",
            "Epoch 541/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2946\n",
            "Epoch 542/750\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2935\n",
            "Epoch 543/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2894\n",
            "Epoch 544/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2913\n",
            "Epoch 545/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2948\n",
            "Epoch 546/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3007\n",
            "Epoch 547/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2982\n",
            "Epoch 548/750\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.3036\n",
            "Epoch 549/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3068\n",
            "Epoch 550/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2953\n",
            "Epoch 551/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3008\n",
            "Epoch 552/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3040\n",
            "Epoch 553/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2987\n",
            "Epoch 554/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3005\n",
            "Epoch 555/750\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2966\n",
            "Epoch 556/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2918\n",
            "Epoch 557/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3055\n",
            "Epoch 558/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2962\n",
            "Epoch 559/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2984\n",
            "Epoch 560/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2975\n",
            "Epoch 561/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2854\n",
            "Epoch 562/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2852\n",
            "Epoch 563/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2937\n",
            "Epoch 564/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2896\n",
            "Epoch 565/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2992\n",
            "Epoch 566/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2984\n",
            "Epoch 567/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2955\n",
            "Epoch 568/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2923\n",
            "Epoch 569/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2935\n",
            "Epoch 570/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2912\n",
            "Epoch 571/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3001\n",
            "Epoch 572/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2908\n",
            "Epoch 573/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2965\n",
            "Epoch 574/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2816\n",
            "Epoch 575/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2983\n",
            "Epoch 576/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2893\n",
            "Epoch 577/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3036\n",
            "Epoch 578/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2939\n",
            "Epoch 579/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2873\n",
            "Epoch 580/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3040\n",
            "Epoch 581/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2913\n",
            "Epoch 582/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3010\n",
            "Epoch 583/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2925\n",
            "Epoch 584/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2983\n",
            "Epoch 585/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3001\n",
            "Epoch 586/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2849\n",
            "Epoch 587/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2986\n",
            "Epoch 588/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2963\n",
            "Epoch 589/750\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.2880\n",
            "Epoch 590/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2989\n",
            "Epoch 591/750\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2958\n",
            "Epoch 592/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3034\n",
            "Epoch 593/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2889\n",
            "Epoch 594/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2941\n",
            "Epoch 595/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2956\n",
            "Epoch 596/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2921\n",
            "Epoch 597/750\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2899\n",
            "Epoch 598/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2874\n",
            "Epoch 599/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2933\n",
            "Epoch 600/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2841\n",
            "Epoch 601/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2843\n",
            "Epoch 602/750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2927\n",
            "Epoch 603/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2899\n",
            "Epoch 604/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2849\n",
            "Epoch 605/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2894\n",
            "Epoch 606/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2916\n",
            "Epoch 607/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2935\n",
            "Epoch 608/750\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2882\n",
            "Epoch 609/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2930\n",
            "Epoch 610/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2937\n",
            "Epoch 611/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2871\n",
            "Epoch 612/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2879\n",
            "Epoch 613/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2930\n",
            "Epoch 614/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2955\n",
            "Epoch 615/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2868\n",
            "Epoch 616/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2910\n",
            "Epoch 617/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2963\n",
            "Epoch 618/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3002\n",
            "Epoch 619/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2834\n",
            "Epoch 620/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2905\n",
            "Epoch 621/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2902\n",
            "Epoch 622/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2926\n",
            "Epoch 623/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2965\n",
            "Epoch 624/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2870\n",
            "Epoch 625/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2905\n",
            "Epoch 626/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2964\n",
            "Epoch 627/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3022\n",
            "Epoch 628/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2859\n",
            "Epoch 629/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2883\n",
            "Epoch 630/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2978\n",
            "Epoch 631/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2939\n",
            "Epoch 632/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2972\n",
            "Epoch 633/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2981\n",
            "Epoch 634/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2862\n",
            "Epoch 635/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2857\n",
            "Epoch 636/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2891\n",
            "Epoch 637/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2882\n",
            "Epoch 638/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2873\n",
            "Epoch 639/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2932\n",
            "Epoch 640/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3016\n",
            "Epoch 641/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2873\n",
            "Epoch 642/750\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.2899\n",
            "Epoch 643/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2962\n",
            "Epoch 644/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2992\n",
            "Epoch 645/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2985\n",
            "Epoch 646/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2912\n",
            "Epoch 647/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2833\n",
            "Epoch 648/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2903\n",
            "Epoch 649/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2946\n",
            "Epoch 650/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2896\n",
            "Epoch 651/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2877\n",
            "Epoch 652/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2921\n",
            "Epoch 653/750\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.2895\n",
            "Epoch 654/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2859\n",
            "Epoch 655/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2841\n",
            "Epoch 656/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2847\n",
            "Epoch 657/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2819\n",
            "Epoch 658/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2964\n",
            "Epoch 659/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2922\n",
            "Epoch 660/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2777\n",
            "Epoch 661/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2994\n",
            "Epoch 662/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2961\n",
            "Epoch 663/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2834\n",
            "Epoch 664/750\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.2904\n",
            "Epoch 665/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2990\n",
            "Epoch 666/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2874\n",
            "Epoch 667/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2857\n",
            "Epoch 668/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2849\n",
            "Epoch 669/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2886\n",
            "Epoch 670/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2933\n",
            "Epoch 671/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2890\n",
            "Epoch 672/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2903\n",
            "Epoch 673/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2889\n",
            "Epoch 674/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2852\n",
            "Epoch 675/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2886\n",
            "Epoch 676/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2886\n",
            "Epoch 677/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2820\n",
            "Epoch 678/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2860\n",
            "Epoch 679/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2898\n",
            "Epoch 680/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2912\n",
            "Epoch 681/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2874\n",
            "Epoch 682/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2896\n",
            "Epoch 683/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2884\n",
            "Epoch 684/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2907\n",
            "Epoch 685/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2920\n",
            "Epoch 686/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2945\n",
            "Epoch 687/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2857\n",
            "Epoch 688/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2855\n",
            "Epoch 689/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2974\n",
            "Epoch 690/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2910\n",
            "Epoch 691/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2911\n",
            "Epoch 692/750\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2884\n",
            "Epoch 693/750\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2918\n",
            "Epoch 694/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2892\n",
            "Epoch 695/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2896\n",
            "Epoch 696/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2891\n",
            "Epoch 697/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2996\n",
            "Epoch 698/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2882\n",
            "Epoch 699/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2905\n",
            "Epoch 700/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2962\n",
            "Epoch 701/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2825\n",
            "Epoch 702/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2921\n",
            "Epoch 703/750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2879\n",
            "Epoch 704/750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2907\n",
            "Epoch 705/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2837\n",
            "Epoch 706/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2805\n",
            "Epoch 707/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2866\n",
            "Epoch 708/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2866\n",
            "Epoch 709/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2928\n",
            "Epoch 710/750\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3038\n",
            "Epoch 711/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2864\n",
            "Epoch 712/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2955\n",
            "Epoch 713/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2856\n",
            "Epoch 714/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2883\n",
            "Epoch 715/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2962\n",
            "Epoch 716/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2819\n",
            "Epoch 717/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2874\n",
            "Epoch 718/750\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2804\n",
            "Epoch 719/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2865\n",
            "Epoch 720/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2873\n",
            "Epoch 721/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2900\n",
            "Epoch 722/750\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 0.2849\n",
            "Epoch 723/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2921\n",
            "Epoch 724/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2887\n",
            "Epoch 725/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2871\n",
            "Epoch 726/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2847\n",
            "Epoch 727/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2980\n",
            "Epoch 728/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2850\n",
            "Epoch 729/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2938\n",
            "Epoch 730/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2863\n",
            "Epoch 731/750\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2823\n",
            "Epoch 732/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2847\n",
            "Epoch 733/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2843\n",
            "Epoch 734/750\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2841\n",
            "Epoch 735/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2901\n",
            "Epoch 736/750\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2904\n",
            "Epoch 737/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2897\n",
            "Epoch 738/750\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2920\n",
            "Epoch 739/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2944\n",
            "Epoch 740/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2870\n",
            "Epoch 741/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2909\n",
            "Epoch 742/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2874\n",
            "Epoch 743/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2842\n",
            "Epoch 744/750\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2958\n",
            "Epoch 745/750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2896\n",
            "Epoch 746/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2904\n",
            "Epoch 747/750\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2819\n",
            "Epoch 748/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2943\n",
            "Epoch 749/750\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2852\n",
            "Epoch 750/750\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2826\n",
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
            "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
            "learning rate 0.1 number trees 200 maximum depth 10 minimum rows 5 AUC 0.9388246400755252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "DneUhbRaCj2l",
        "outputId": "65f36b5e-c6ba-4755-e74e-7ec02f31a924"
      },
      "source": [
        "# results on hold out test set\n",
        "GBMdata_hold = h2o.H2OFrame(hold_out_policies)\n",
        "GBMdata_hold[(claim_policies.shape[1]-1)] = GBMdata_hold[(claim_policies.shape[1]-1)].asfactor()\n",
        "pred_h2o_hold = air_model.predict(GBMdata_hold)\n",
        "perf_hold = air_model.model_performance(GBMdata_hold)\n",
        "\n",
        "print(gen,\"AUC\", perf_hold.auc())\n",
        "\n",
        "pred_h2o_hold = pred_h2o_hold.as_data_frame().to_numpy()\n",
        "classification_h2o_hold = classification(pred_h2o_hold[:,2],0.3) # perf_hold.F1()[0][0]\n",
        "cm_hold = confusion_matrix(Y_hold_out, classification_h2o_hold)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_hold, display_labels=[0,1])\n",
        "disp.plot()\n",
        "\n",
        "fpr_hold, tpr_hold, thresholds_hold = metrics.roc_curve(Y_hold_out, pred_h2o_hold[:,2], pos_label=1)\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr_hold, tpr_hold, color='darkorange', lw=lw, label='ROC curve')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('GBM_ROC.png')\n",
        "plt.show()\n",
        "\n",
        "undersample = RandomUnderSampler(sampling_strategy=1)\n",
        "X_holdout_bal, y_holdout_bal = undersample.fit_resample(X_hold_out, Y_hold_out)\n",
        "holdout_bal = np.append(X_holdout_bal,np.expand_dims(y_holdout_bal,axis = 1),axis=1)\n",
        "\n",
        "GBMdata_holdbal = h2o.H2OFrame(holdout_bal)\n",
        "GBMdata_holdbal[(claim_policies.shape[1]-1)] = GBMdata_holdbal[(claim_policies.shape[1]-1)].asfactor()\n",
        "pred_h2o_holdbal = air_model.predict(GBMdata_holdbal)\n",
        "perf_holdbal = air_model.model_performance(GBMdata_holdbal)\n",
        "\n",
        "pred_h2o_holdbal = pred_h2o_holdbal.as_data_frame().to_numpy()\n",
        "classification_h2o_holdbal = classification(pred_h2o_holdbal[:,2],0.3) # perf_hold.F1()[0][0]\n",
        "cm_holdbal = confusion_matrix(y_holdout_bal, classification_h2o_holdbal)\n",
        "dispbal = ConfusionMatrixDisplay(confusion_matrix=cm_holdbal, display_labels=[0,1])\n",
        "dispbal.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
            "<function VAE_synthesise at 0x7fcd716c4c20> AUC 0.8134395858025077\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fcd60edaa10>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrpQrXmoq_6H"
      },
      "source": [
        "# performance metrics at different thresholds\n",
        "print(perf_holdbal.auc())\n",
        "F1_graph = perf_holdbal.F1(thresholds = [0.40,0.25,0.10,0.05,0.01,0.005,0.0025])\n",
        "recall_graph = perf_holdbal.recall(thresholds = [0.40,0.25,0.10,0.05,0.01,0.005,0.0025])\n",
        "precision_graph = perf_holdbal.precision(thresholds = [0.40,0.25,0.10,0.05,0.01,0.005,0.0025])\n",
        "accuracy_graph = perf_holdbal.accuracy(thresholds = [0.40,0.25,0.10,0.05,0.01,0.005,0.0025])\n",
        "\n",
        "performance_graphs = np.ndarray((7,5))\n",
        "\n",
        "i = 0\n",
        "while i < 7:\n",
        "  performance_graphs[i,0] = F1_graph[i][0]\n",
        "  performance_graphs[i,1] = F1_graph[i][1]\n",
        "  performance_graphs[i,2] = recall_graph[i][1]\n",
        "  performance_graphs[i,3] = precision_graph[i][1]\n",
        "  performance_graphs[i,4] = accuracy_graph[i][1]\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BVFC0Y7xC6J",
        "outputId": "4ff5bc51-0c7c-4231-9188-63a4cfe752a1"
      },
      "source": [
        "performance_graphs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4       , 0.62857143, 0.47826087, 0.91666667, 0.7173913 ],\n",
              "       [0.25      , 0.61111111, 0.47826087, 0.84615385, 0.69565217],\n",
              "       [0.1       , 0.57894737, 0.47826087, 0.73333333, 0.65217391],\n",
              "       [0.05      , 0.61538462, 0.52173913, 0.75      , 0.67391304],\n",
              "       [0.01      , 0.68292683, 0.60869565, 0.77777778, 0.7173913 ],\n",
              "       [0.005     , 0.68292683, 0.60869565, 0.77777778, 0.7173913 ],\n",
              "       [0.0025    , 0.68181818, 0.65217391, 0.71428571, 0.69565217]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Qsp_0QOt1A0o",
        "outputId": "6f74dfa8-0734-4b33-cbe3-84f3fc531337"
      },
      "source": [
        "# proabbility distribution of policies being a claim policy\n",
        "plt.hist(pred_h2o_hold[:,2], bins=10, density=True, alpha=0.6, color='g')\n",
        "plt.xlabel('Probability of Claim Policy')\n",
        "plt.ylabel('Relative Frequency')\n",
        "plt.title('Claim Policy Probability Predictions for Test Set')\n",
        "plt.savefig(('prob_density.png'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYuk_BueqW9h"
      },
      "source": [
        "# identifying false neagtive predictions for review\n",
        "index = np.where(Y_hold_out != classification_h2o_hold)[0]\n",
        "incorrect_predsx = X_hold_out[index,:]\n",
        "incorrect_predsy = Y_hold_out[index]\n",
        "index = np.where(incorrect_predsy == 1)[0]\n",
        "incorrect_predsx = incorrect_predsx[index,:]\n",
        "w = csv.writer(open(\"incorrect_preds.csv\", \"w\"))\n",
        "for i in incorrect_predsx:\n",
        "  w.writerow(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4NxPNU6QTFR",
        "outputId": "68f1fff0-abb6-493d-b833-5d00fdccd9ec"
      },
      "source": [
        "# comparing predictions against actual outcome\n",
        "probs_table = np.empty((2,1417))\n",
        "probs_table[0,:] = pred_h2o_hold[:,2]\n",
        "probs_table[1,:] = Y_hold_out\n",
        "print(tabulate(probs_table))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------  -----------  --------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ----------  -----------  --------  -----------  --------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  ---------  -----------  -----------  --------  -----------  -----------  ----------  -----------  -----------  -----------  ----------  -----------  ----------  ---------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -------  -----------  -----------  -----------  -----------  ---------  ----------  --------  ---------  ----------  -----------  ----------  ---------  -----------  ----------  -----------  ---------  ---------  ----------  -----------  ----------  ----------  -----------  --------  -----------  -----------  -----------  -----------  --------  -----------  -----------  ---------  ---------  -----------  ---------  -----------  -----------  ----------  ----------  -----------  --------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ---------  ----------  --------  -----------  --------  -----------  -----------  -----------  ----------  --------  ---------  -----------  ----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  --------  ----------  ---------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  ----------  --------  ---------  ----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  --------  -----------  ---------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  ---------  -------  -----------  --------  -----------  ---------  -----------  ---------  ----------  ---------  -----------  ----------  ---------  -----------  -----------  ----------  -------  --------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  ---------  -----------  -----------  --------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ---------  -----------  -----------  ---------  --------  -----------  -----------  -----------  -----------  ----------  ----------  -----------  -----------  ----------  -----------  ----------  -----------  ----------  -----------  -----------  ---------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  ---------  ----------  -----------  -----------  -----------  ----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  ----------  --------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ----------  ----------  ----------  --------  -----------  ----------  -----------  ---------  -----------  --------  ----------  -----------  -----------  --------  --------  --------  --------  -----------  -----------  --------  ----------  -----------  ---------  -----------  -----------  ---------  -----------  --------  ----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  ---------  -----------  --------  ---------  ---------  ---------  -----------  ----------  -----------  -----------  ---------  -----------  -----------  --------  -----------  --------  ----------  -----------  --------  ---------  ---------  -----------  -----------  --------  ----------  ----------  -----------  --------  ---------  -----------  ----------  -----------  --------  ---------  -----------  ----------  --------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  --------  ---------  ----------  -----------  -----------  ----------  -----------  ----------  -----------  --------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  ----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ---------  ----------  -----------  ----------  -----------  -----------  -----------  ----------  ----------  --------  -----------  -----------  --------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ---------  ----------  -----------  -----------  ----------  --------  -----------  ----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  --------  ----------  --------  ----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  ---------  -----------  ----------  -----------  -----------  ----------  ----------  -----------  ----------  ---------  -----------  ---------  -----------  -----------  ---------  -----------  ---------  --------  -----------  ----------  ---------  -----------  -----------  ---------  -----------  -----------  -----------  ----------  ----------  -----------  -----------  --------  -----------  ----------  ----------  -----------  -----------  ---------  -----------  -----------  ---------  -----------  ---------  -----------  -----------  -----------  -----------  ----------  -----------  --------  -----------  -----------  ----------  -----------  ----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  ---------  -----------  -----------  ----------  --------  --------  --------  -----------  -----------  -----------  -------  -----------  --------  --------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ----------  -----------  -----------  -----------  -----------  ----------  ----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ---------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ----------  ----------  -----------  -----------  -----------  -----------  ----------  ---------  ---------  -----------  -----------  --------  -----------  -----------  ---------  ----------  -----------  --------  -----------  -----------  ----------  -----------  --------  -----------  -----------  --------  -----------  -----------  -----------  ----------  -----------  --------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  --------  -----------  -----------  ----------  -----------  -----------  -----------  --------  -----------  ---------  -----------  -----------  ---------  -----------  -----------  ----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ----------  -----------  ----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  --------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ----------  --------  -----------  ---------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -------  ----------  -----------  ----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  ----------  -------  -----------  ---------  -----------  ----------  -----------  -----------  -----------  -----------  --------  ----------  ----------  -----------  -----------  ----------  -----------  -----------  --------  -----------  -----------  ----------  -----------  -----------  --------  -----------  --------  ----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ---------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ----------  -----------  -----------  --------  ---------  -----------  -----------  -----------  -----------  -----------  ----------  -------  ----------  -------  ---------  --------  -----------  ---------  -----------  ----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  --------  -----------  --------  -----------  ----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  --------  -----------  ----------  -----------  ----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  --------  --------  -----------  --------  --------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  ---------  ---------  -----------  --------  ----------  --------  -----------  -----------  -----------  ----------  -----------  --------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -------  -----------  -----------  -----------  --------  -----------  ----------  --------  --------  -----------  --------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ---------  ----------  -----------  -----------  ----------  ----------  --------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ---------  -----------  ---------  -----------  ----------  -----------  -----------  -----------  ----------  -----------  --------  -----------  -----------  ----------  -----------  ----------  -----------  -----------  ----------  ----------  -----------  -----------  ----------  -----------  --------  ----------  -----------  -----------  ----------  -----------  -----------  ---------  -----------  -----------  ----------  -----------  ----------  --------  --------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  --------  -------  -----------  ----------  --------  -----------  -----------  ---------  ---------  -----------  -----------  ----------  ----------  ----------  --------  -----------  -----------  -----------  -----------  -----------  ----------  ----------  ---------  -----------  -----------  -----------  -----------  --------  -----------  ----------  ---------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  --------  -----------  -----------  -----------  -----------  ----------  ----------  ---------  -----------  --------  --------  -----------  -----------  --------  ----------  -----------  -----------  -----------  ---------  ----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  ----------  ---------  --------  -----------  -----------  ---------  ----------  ----------  -----------  -----------  --------  --------  -----------  ----------  --------  -----------  ----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ----------  ----------  -----------  -----------  -----------  -----------  -----------  ---------  ----------  -----------  ----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  --------  -----------  -----------  ---------  -------  --------  -----------  -----------  --------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  ----------  -----------  ----------  -----------  -----------  ----------  ----------  -----------  --------  -----------  --------  -----------  ----------  -----------  -----------  -----------  --------  -----------  --------  -----------  -----------  -----------  --------  -----------  -----------  ----------  --------  -----------  --------  -----------  ----------  ---------  -----------  ---------  --------  ----------  -------  -----------  -----------  ---------  -----------  ----------  ----------  -----------  -----------  ----------  ----------  ----------  -----------  -----------  --------  -----------  -----------  -----------  ----------  --------  -----------  -------  -------  -----------  -----------  -----------  -----------  --------  --------  -----------  ----------  ----------  -----------  --------  ----------  --------  --------  -----------  -----------  -----------  --------  -----------  ---------  ----------  -----------  --------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ----------  -----------  ---------  --------  -----------  -----------  ---------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  ---------  -----------  -----------  ---------  --------  --------  ---------  ----------  -----------  ----------  ---------  ---------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  ---------  ---------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  --------  -----------  ---------  ----------  -----------  --------  -----------  -----------  ----------  -----------  ---------  -----------  -----------  -----------  -----------  ----------  --------  -----------  -----------  ---------  -----------  --------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  --------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ----------  -----------  -----------  --------  ----------  --------  -----------  ----------  -----------  -----------  --------  -----------  -----------  ----------  -----------  ---------  -----------  ---------  -----------  -----------  --------  ---------  -----------  -----------  ---------  -----------  ----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -------  -----------  -----------  -----------  -----------  ----------  ---------  ----------  -----------  -----------  --------  -----------  ----------  -----------  -----------  ---------  -----------  -----------  ---------  ----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ---------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ----------  -----------  --------  ----------  ----------  -----------  -----------  -----------\n",
            "8.31785e-05  9.12686e-06  0.833321  0.000450654  1.16847e-06  0.000117688  3.62724e-05  0.624748  2.03554e-07  0.000152279  1.46149e-06  0.00106209  6.25162e-06  0.264014  6.96719e-05  0.950561  9.4566e-08  1.76195e-07  1.47346e-05  5.40542e-05  1.09989e-06  1.10337e-06  7.25109e-06  0.801158  0.0002997  2.94371e-07  4.22615e-07  0.999798  2.93888e-05  1.70675e-07  0.00953881  4.33609e-05  4.17534e-06  2.57457e-05  0.00244895  2.02368e-05  0.00160447  0.0106521  5.55177e-05  7.86953e-06  4.5528e-06  9.22179e-07  1.46676e-07  8.57912e-07  0.000522098  1.4087e-05  0.000811722  7.40061e-06  1.923e-06  1.90051e-07  1.51178e-06  1.17332e-07  2.10127e-06  8.59035e-08  1.15414e-05  0.0552794  1.37262e-06  0.35453  3.16706e-07  1.07427e-06  0.000822079  0.000214611  0.0899341  0.00104035  0.999956  0.0298714  0.00204482  2.87336e-06  3.5348e-07  0.0070862  1.63796e-06  0.00508975  7.49405e-08  2.144e-07  0.0027849  3.1669e-05  5.08341e-05  1.3267e-05  0.00616756  1.75128e-05  0.696933  1.34137e-06  0.000568804  0.000258231  3.45333e-07  0.989964  0.000230909  0.000609766  0.0386836  0.0630558  4.14086e-06  0.0109539  4.65052e-06  5.13712e-06  0.00108686  0.00839317  0.000144626  0.968809  1.52685e-06  0.000149563  1.16655e-07  4.88369e-07  0.0655116  0.000453312  5.10883e-06  5.58027e-07  3.22168e-05  1.53156e-06  6.31656e-06  9.52002e-08  1.25795e-06  0.0155263  0.00182558  0.547851  1.36821e-07  0.999935  9.85287e-07  6.12964e-07  0.000158609  0.00131162  0.456089  0.0394257  6.87206e-06  0.00641693  0.0308494  1.09729e-07  5.38963e-06  1.52896e-06  2.84155e-05  3.74456e-07  2.89704e-05  0.00542788  1.32912e-06  0.000795166  0.000128082  0.000127922  0.976243  3.5332e-05  0.0019791  1.19234e-05  0.000449227  9.21472e-06  2.89148e-06  0.926804  0.000960889  4.97763e-07  0.000609585  2.81603e-05  5.48172e-05  4.6965e-06  0.999949  0.0148761  0.00360531  3.44022e-05  1.65232e-06  8.57566e-08  7.49633e-05  1.28697e-06  7.8219e-07  2.17282e-06  5.87437e-08  0.977397  8.04401e-07  0.0274686  8.75004e-05  1.30784e-05  0.0131666  2.44333e-05  7.86917e-07  1.16144e-06  5.44177e-05  7.64341e-05  0.0015621  0.37442  2.23781e-06  0.145058  4.82909e-05  0.0207005  0.000336702  0.0404384  0.00628441  0.0526741  3.71315e-05  6.0175e-07  2.842e-05  1.23974e-06  6.49916e-05  0.00117138  0.27981  0.034883  6.48213e-07  8.52613e-06  2.3571e-06  9.88191e-05  8.57823e-07  3.64989e-07  4.45283e-05  6.87829e-08  0.998625  6.36916e-05  0.000878408  0.000124947  5.54347e-06  7.86792e-05  8.82994e-05  0.118501  5.06182e-07  7.28688e-06  0.0317488  3.24187e-06  0.000136504  0.999816  4.11868e-06  0.00322701  0.000120144  3.20895e-05  1.04159e-06  0.000201453  3.40271e-06  5.81042e-07  2.43035e-05  1.89813e-06  0.00315734  0.0143892  3.59016e-06  4.44264e-06  0.0162022  0.152975  8.71292e-06  3.92827e-07  0.000121744  0.000487309  0.00102603  0.00141825  1.47706e-05  0.000176864  0.00384605  4.71025e-08  0.00146048  6.01576e-08  0.00080843  0.000551888  2.81318e-08  0.0228425  1.11232e-05  0.0692727  6.32647e-05  1.42681e-07  1.53821e-07  3.15035e-05  2.55917e-06  0.0527428  1.4422e-05  1.32984e-07  1.01334e-07  9.86769e-07  0.00611397  0.107727  4.55469e-08  1.00655e-07  1.29391e-05  5.19566e-07  9.17131e-05  1.06127e-06  1.48135e-06  8.06291e-08  0.920945  4.51795e-06  0.428141  1.79699e-06  7.70985e-07  1.29753e-05  0.000134744  4.51627e-07  0.000139979  4.43346e-05  0.00265222  5.93085e-06  1.22754e-05  5.16943e-06  5.95341e-05  2.74961e-06  5.47353e-07  0.0269529  7.98481e-07  2.31663e-05  0.0103964  7.32605e-06  9.08639e-05  4.33199e-06  1.11104e-05  0.00191927  0.156725  0.00568358  8.99804e-06  1.40552e-06  2.01989e-05  2.06684e-05  3.29576e-06  1.54152e-06  0.00743465  0.00188718  0.00110231  0.00101842  0.206645  1.02485e-05  7.7384e-05  0.000398081  0.0311762  3.14674e-06  0.694387  0.00265841  1.76117e-07  3.55579e-07  0.894737  0.374765  0.264165  0.014306  2.86765e-05  0.000824334  0.907794  0.00148143  6.11584e-08  0.0598461  9.32651e-06  5.21656e-06  0.0563804  7.87257e-06  0.427523  0.00102286  0.000440331  2.55231e-05  0.000698175  0.0247573  0.000735978  1.26112e-06  0.000508923  2.83592e-06  4.51516e-06  0.000232008  2.93882e-07  0.0267163  2.57496e-08  8.40787e-07  0.0228567  5.04436e-06  0.749574  0.0093491  0.0193522  2.035e-05  9.90706e-07  0.00108597  1.71756e-05  2.87778e-06  0.0119101  1.37081e-06  0.000202983  0.251473  1.71598e-05  0.283794  0.00185568  6.40398e-06  0.261976  0.0754064  0.0198554  6.55283e-08  3.43607e-07  0.997944  2.1387e-06  0.00156781  1.78295e-06  0.999621  0.0166605  1.39672e-05  0.00328068  0.000250265  0.640314  0.0593839  1.73081e-07  0.00273223  0.998902  4.69645e-05  9.09033e-08  1.03379e-07  4.47662e-05  0.00117779  0.000717258  2.38922e-06  5.65009e-05  0.000491509  0.172774  0.0230324  4.9693e-05  8.31511e-07  8.31954e-05  0.00261752  0.000548578  5.8291e-06  9.04434e-05  0.681814  0.000160063  0.999819  4.76107e-07  7.89246e-07  7.40502e-07  4.58585e-05  0.000467406  5.27225e-05  0.331014  3.23974e-06  3.60353e-06  0.00816671  1.97481e-06  3.18994e-07  3.05422e-08  6.3414e-08  1.74836e-06  1.11158e-06  0.000275996  5.76411e-05  0.000420633  0.139267  0.000394525  2.44337e-06  5.94545e-07  0.0098502  0.00545447  0.000129258  0.00141744  3.17726e-05  1.60679e-07  0.000237778  0.00187812  0.00156784  0.917609  1.16447e-06  3.70158e-07  0.998975  0.00392165  3.57268e-06  2.56064e-07  1.20569e-05  7.36298e-06  1.07123e-05  0.000247251  0.00260363  0.0323345  0.00063031  1.06597e-06  2.46744e-05  9.9822e-08  0.109225  4.86599e-05  0.00386954  0.000118151  2.12759e-07  0.000120682  8.26606e-07  1.0279e-06  0.000739352  1.09099e-05  0.000286182  2.40213e-07  0.03192  0.00319493  7.46909e-06  3.38864e-06  1.06216e-07  4.06109e-07  3.60962e-07  3.77104e-08  4.87963e-05  4.48987e-05  0.826884  0.993831  0.00391776  0.538049  3.3647e-06  1.43756e-05  0.000521487  0.000480617  0.0417926  0.000946497  4.72754e-06  0.000173169  0.0059487  0.000892462  0.00046124  3.49606e-07  0.000214131  2.8723e-06  5.4609e-07  0.000135489  0.00723394  0.0123405  8.73218e-05  0.0128402  2.18976e-05  2.59727e-07  0.0679066  5.80173e-05  0.0137177  0.824208  4.26784e-06  2.1311e-06  0.0332968  3.52367e-06  5.71731e-07  0.0633184  0.000140002  3.15077e-07  0.000472605  0.00046659  8.8286e-07  0.000957643  3.94309e-05  0.044801  2.89616e-07  1.5479e-05  0.00448096  0.000774009  1.31916e-05  0.0224344  1.39211e-05  1.32741e-06  0.0225603  5.38027e-07  0.0953567  1.09691e-07  2.54607e-06  4.10268e-06  4.15652e-06  3.2566e-07  5.44378e-07  0.976006  0.000122342  6.14534e-06  0.00235584  1.34271e-05  0.00036284  0.00353278  0.000259292  1.46819e-06  4.57749e-05  3.04286e-05  9.29173e-05  4.33825e-06  0.000844133  0.0476934  0.000469951  3.83753e-07  0.0287279  2.93631e-08  2.20789e-06  0.00599311  0.109197  0.848641  0.962474  6.49631e-07  8.56681e-08  1.89819e-06  0.99999  5.56988e-07  0.076522  0.841997  2.05764e-06  1.04033e-05  5.91484e-06  1.48429e-05  3.27673e-08  0.000952788  0.00825694  1.16782e-06  0.00012714  5.47602e-05  9.98532e-07  5.04097e-06  4.52306e-05  0.00898942  2.3181e-06  0.938625  0.000982098  5.26718e-08  9.93744e-05  4.39138e-08  8.83817e-07  0.000452882  0.000610513  0.995667  2.86785e-07  3.23372e-05  1.10783e-07  0.0062307  3.65977e-07  0.00211395  0.000730108  1.56979e-05  3.76843e-06  3.60807e-05  6.88838e-07  0.00191283  0.000306702  0.992311  1.14982e-05  1.07621e-07  1.06315e-06  6.37303e-07  1.46319e-05  4.23527e-05  0.523259  0.000318992  2.03884e-06  1.90788e-06  7.4369e-07  0.00998213  2.84293e-07  6.66384e-06  5.08337e-06  1.09903e-05  0.00698182  0.0019934  5.649e-05  0.000215227  3.46218e-07  0.027638  2.02599e-06  4.97982e-07  0.0323322  0.00584297  3.42232e-07  0.988143  0.000238919  1.07455e-07  0.00543288  9.38896e-05  0.176466  3.25085e-05  2.88124e-05  0.372474  5.45115e-07  2.31469e-05  4.35306e-07  3.2107e-05  1.00968e-06  0.169594  0.000190257  0.0205446  2.98996e-05  5.46243e-06  1.21058e-07  7.41895e-07  3.00252e-05  0.24953  7.57986e-06  9.74879e-05  2.18224e-06  4.63189e-06  2.91246e-05  1.88519e-05  3.1677e-06  0.962876  0.000795438  7.42914e-05  0.00897398  4.50898e-05  1.29655e-06  1.74783e-05  0.109355  1.80584e-05  0.0026487  6.61584e-07  1.72067e-07  0.0492837  3.97872e-07  1.68217e-05  0.00397234  2.9834e-06  7.04347e-06  9.85709e-05  0.000216027  7.96969e-08  4.02949e-07  8.99553e-08  3.04795e-06  1.32338e-05  0.00412255  0.00433366  0.000121407  5.9467e-08  7.48208e-05  3.37447e-08  0.0424106  0.000672712  2.64825e-05  2.84974e-07  2.60125e-06  9.58601e-06  0.00577174  1.10542e-05  3.82203e-06  2.76336e-06  0.056511  0.000369563  0.185073  7.14228e-06  1.63115e-06  4.24789e-05  1.22415e-06  9.15021e-07  3.85737e-07  0.000792272  1.6552e-06  4.74553e-05  0.00939194  0.999978  1.73484e-07  0.0880403  3.94846e-07  0.0324496  1.15253e-05  8.89349e-07  6.02982e-05  1.80174e-05  1.41003e-06  5.89161e-06  0.942048  0.86539  0.00139523  9.54607e-05  2.7853e-05  3.66638e-07  0.000899482  4.79256e-05  5.70919e-06  0.008412  2.77122e-05  0.000173666  0.000395755  8.83586e-05  0.00473611  0.83203  8.24204e-05  0.0265918  1.49631e-06  1.8678e-06  2.85373e-06  0.000299368  4.01559e-05  1.12254e-05  0.299743  0.00275373  7.0942e-08  1.37882e-07  7.03857e-06  7.4505e-05  5.19465e-05  4.82387e-07  0.105808  9.94584e-05  1.80313e-05  0.00165675  1.15911e-07  6.30359e-07  0.488011  0.000380401  0.353762  0.00147097  1.34682e-07  0.00210808  1.29974e-07  1.12574e-05  0.000886848  1.18855e-05  1.80293e-05  0.00679613  4.24253e-05  0.0137599  0.000244461  0.000190843  0.000104312  0.227408  4.57787e-05  1.98066e-05  0.000283576  0.00324563  1.69541e-05  5.16101e-06  0.763072  0.0653847  4.86486e-05  1.39812e-05  2.70937e-06  2.20926e-07  3.13205e-06  5.6688e-07  0.36722  0.00877717  0.46315  0.0176145  0.685257  9.24321e-06  0.0517247  3.53102e-07  0.00176938  2.03127e-07  0.000224385  0.00378577  1.79981e-05  0.000149701  0.000690093  6.53212e-05  7.74546e-05  0.000482204  1.65831e-06  0.00992918  9.85689e-06  0.385668  4.94969e-05  0.124718  3.35438e-05  0.00069764  8.19543e-07  2.59131e-05  0.982407  3.63333e-05  0.000512448  7.10857e-06  4.17406e-05  0.973682  4.33194e-07  0.00113219  1.27743e-06  0.00644675  9.75181e-07  0.0189284  4.93963e-06  6.33978e-07  1.50725e-07  0.000217231  2.64914e-07  0.993465  0.001372  2.87976e-06  0.957474  0.999624  1.53922e-06  1.60658e-06  8.05465e-06  1.94098e-06  4.75824e-07  7.631e-08  1.80803e-06  0.000493523  1.94765e-06  0.0144994  0.0178648  9.89835e-08  0.827488  0.00184082  0.228381  4.46855e-06  7.18078e-08  1.91735e-07  0.00067071  9.22819e-06  0.424916  0.0827428  2.14596e-05  4.54553e-07  3.89298e-05  2.49781e-06  3.58237e-07  3.27517e-06  0.99259  9.60437e-08  3.30466e-07  7.70855e-07  0.999954  5.60756e-07  0.00560361  0.020533  0.409142  2.23877e-06  0.101316  8.55816e-07  6.91141e-08  3.0623e-06  4.53092e-06  0.000243239  0.000586696  0.000457762  5.58444e-07  0.994156  2.41554e-06  0.0372647  0.000141878  1.08173e-05  2.25712e-05  3.59755e-07  1.80908e-05  1.31816e-05  1.92094e-06  7.43055e-08  3.65233e-06  0.00222158  0.0113406  3.5866e-05  2.11303e-05  4.49174e-06  8.9082e-05  0.00179452  0.514195  5.12383e-06  4.76111e-07  4.71955e-07  6.37273e-06  0.274338  5.09398e-05  1.30776e-05  0.000101153  0.0443195  0.000661466  0.0251603  4.63612e-06  0.00280733  3.72322e-06  3.64647e-06  3.07901e-06  0.00244332  8.92362e-07  0.990642  7.30675e-06  3.58501e-08  0.00347084  0.000305427  0.00343295  2.13764e-05  2.48819e-07  0.00015748  0.00109219  0.000404995  9.30145e-06  0.00259872  1.75587e-05  0.994211  0.00143932  6.91383e-07  0.000167059  0.00121839  5.15431e-05  6.55564e-05  0.0077592  7.99593e-06  6.14861e-05  0.00012016  4.42667e-06  0.00272634  0.102598  0.999295  0.000269425  0.00132765  1.59949e-05  4.98224e-06  3.00692e-06  1.65008e-07  1.84294e-06  4.15333e-08  5.93982e-07  9.57222e-07  6.21922e-08  7.72031e-08  0.569495  0.566558  0.98648  8.00001e-05  0.00400095  0.768615  1.38854e-06  2.98652e-05  0.0168556  0.0242907  7.60025e-06  6.60568e-07  0.00216975  0.00106621  0.00244703  0.994592  2.00792e-05  7.27072e-08  1.55791e-05  2.76437e-06  0.000403127  0.00725993  6.1656e-05  0.0175041  7.28121e-07  3.14477e-05  0.000140609  1.11525e-06  1.44e-05  0.000318988  2.3693e-05  0.0691308  3.37568e-07  5.16667e-06  2.19221e-06  2.29923e-05  1.12614e-05  0.0123374  4.06321e-06  0.000365834  1.46723e-07  2.95416e-06  2.92212e-08  0.000109529  3.18442e-05  0.775124  0.967328  1.91505e-07  4.29595e-07  5.91417e-05  0.000348355  3.0175e-05  0.00050865  0.0105772  5.85971e-07  0.943121  0.484771  0.000271592  3.30277e-06  0.571628  0.00011981  1.98089e-06  1.11196e-07  9.25043e-07  3.039e-08  0.00289024  1.78222e-05  0.0181525  3.50019e-05  8.76427e-08  9.14423e-07  4.66714e-08  8.02854e-06  2.08909e-07  1.85253e-05  0.00377573  2.33026e-07  5.49757e-07  8.46262e-05  0.000251978  1.88804e-05  0.00199707  0.0011293  0.747712  8.52999e-08  8.78771e-06  0.0856102  0.00223525  9.1209e-06  5.82111e-06  8.13249e-07  0.117183  0.704488  1.98589e-08  1.3887e-07  0.368658  2.21742e-06  0.00212516  2.33056e-06  0.000314167  1.2323e-07  1.35612e-07  5.08097e-07  7.26472e-08  0.000119681  0.810077  8.29406e-06  1.15583e-07  8.59582e-06  5.31664e-06  3.38539e-06  2.6443e-07  0.000210977  2.7905e-08  0.00778806  0.000184904  0.000162257  1.05772e-07  2.10062e-07  3.19182e-07  0.0983387  4.3329e-05  1.49093e-06  1.2785e-06  0.00827462  2.14817e-06  0.000151195  1.54002e-06  1.39737e-06  2.44666e-05  1.47998e-07  0.000173875  0.00308294  0.123753  7.33095e-06  1.11847e-05  0.0178649  0.85069  0.212917  1.73722e-07  7.40217e-05  0.228447  3.99343e-05  1.67087e-05  3.47807e-07  0.00431653  0.000112931  1.08173e-05  4.37753e-05  0.00244926  2.55506e-07  0.00214563  2.88324e-05  3.74581e-05  0.00144032  6.1637e-05  2.04155e-07  0.857916  1.51438e-08  0.535494  1.29299e-06  0.00420926  4.38475e-05  8.95087e-07  4.02218e-08  0.184748  9.84793e-07  0.117375  7.13832e-05  7.27463e-06  3.12244e-06  0.478835  0.000352304  8.97164e-06  0.00245097  0.375513  3.68688e-06  0.220404  1.67819e-07  0.00189986  0.0276152  1.78225e-05  0.0401924  0.999829  0.00109528  0.91937  3.22207e-05  0.000193419  0.0581007  4.11802e-05  0.00100504  5.5288e-07  3.06142e-06  0.000103818  0.00103949  0.00300828  0.00183353  3.81229e-07  0.000371951  0.655193  0.000104332  3.40793e-07  2.64601e-05  3.1121e-07  0.259039  1.24834e-06  0.01695  0.98974  1.18544e-07  4.55033e-07  5.19329e-06  1.51006e-07  0.839962  0.008061  2.02483e-06  9.1342e-08  9.6232e-06  1.62491e-06  0.185682  0.00121608  0.475696  0.626619  3.76808e-07  3.88204e-06  0.000395084  0.265397  2.38692e-06  0.0224088  0.00360993  1.28905e-06  0.325105  1.7979e-05  3.20704e-06  5.02046e-07  0.000147346  7.21658e-05  1.00454e-06  1.07991e-05  0.695045  1.65525e-05  6.04624e-05  4.90654e-07  4.76628e-07  7.59421e-05  2.31662e-06  0.00165704  7.64556e-05  1.09517e-07  0.000960749  0.258104  0.000290648  0.000145235  0.000350808  0.000683605  0.000294036  3.69967e-07  1.68023e-06  2.04998e-07  0.000223643  3.03439e-07  1.61118e-06  3.63141e-06  1.79091e-05  1.1538e-05  0.00313026  8.26694e-06  0.0081879  0.319765  0.000249346  4.33613e-05  0.0818791  6.19969e-07  0.000653217  1.1025e-05  7.90571e-06  3.02575e-07  8.93796e-06  8.40604e-05  2.64692e-05  2.06431e-07  0.150765  0.0327063  3.39732e-06  0.000399361  0.0648051  0.189528  0.232623  0.0582468  5.6948e-07  4.40048e-05  6.3866e-07  0.0418343  0.0042642  0.000325154  5.42869e-07  6.87438e-07  9.15374e-05  0.972369  0.000535886  5.23115e-07  1.67257e-06  0.000262041  0.0243721  0.0552252  2.97489e-05  1.53772e-05  5.40837e-05  0.00454027  2.16132e-07  1.76981e-07  4.40951e-05  2.53823e-05  1.98e-06  0.000110567  0.0665446  4.2397e-06  4.06312e-05  0.998817  1.10212e-06  3.01758e-05  8.1791e-05  1.39772e-06  0.0682749  0.000914464  2.58266e-05  9.55744e-08  0.000219086  1.9552e-06  0.018921  0.000143931  6.64842e-07  6.274e-07  0.000134204  0.775985  0.000160175  8.2132e-05  0.000153552  2.64513e-07  6.72444e-08  5.57956e-05  0.000906726  5.07412e-07  1.07148e-06  1.91691e-05  0.00042755  6.33846e-07  0.010042  1.68358e-07  0.000700382  0.909395  4.42665e-05  0.000641921  8.67498e-07  9.08914e-06  9.65766e-05  0.912117  9.18749e-07  3.88945e-08  6.24797e-05  0.00251174  0.000670966  0.000609538  0.369178  9.6049e-08  0.214488  2.46422e-05  0.00122777  0.000108774  0.000989558  0.975469  5.92791e-05  2.86657e-05  0.00112049  2.28864e-07  3.864e-07  2.02581e-07  0.0775624  8.57968e-07  0.000343266  0.483475  0.0437952  8.14841e-07  1.62012e-06  0.0692252  1.75757e-05  7.9335e-07  0.903815  4.74895e-06  5.76427e-08  2.55581e-06  0.000267194  3.09325e-06  1.91005e-07  0.99908  3.82049e-06  1.13646e-05  4.64847e-05  1.53738e-07  0.00264841  0.0561308  3.9748e-05  9.90026e-07  6.50555e-08  0.111117  7.71086e-07  1.3421e-07  6.43456e-06  8.44906e-07  2.691e-05  0.000230848  2.78244e-06  0.0114168  0.00303167  8.71668e-07  1.82705e-06  3.42088e-06  0.0163698  6.47799e-06  0.000317428  3.47439e-06  1.06044e-06  1.86123e-05  1.15776e-07  2.57346e-05  0.00251274  0.000156621  0.0020494  0.109711  1.91923e-07  3.07051e-07  0.000394669  0.000583556  0.000865674  0.000529007  3.70759e-06  2.52911e-06  0.00238831  5.38137e-07  2.3296e-06  6.65897e-06  0.106548  0.00249766  0.00147333  8.82057e-07  0.000426459  5.53547e-06\n",
            "0            0            1         0            0            0            0            0         0            0            0            0           0            0         0            0         0           0            0            0            0            0            0            0         0          0            0            0         0            0            0           0            0            0            0           0            0           0          0            0            0           0            0            0            0            0           0            0            0          0            0            0            0            0            0            0          0            0        0            0            0            0            0          0           0         0          0           0            0           0          0            0           0            0          0          0           0            0           1           0            0         0            0            0            0            0         0            0            0          0          0            0          0            0            0           0           0            0         0            0            0            0            0          0            0            0            0            0            0            0            0            0          0           0         0            1         0            0            0            0           0         0          0            0           0          0            0            0            0            0            0            0           0            0            1            0            0         0           0          0            0            0            0            0         0            0            0            0            0            0           0         0          0           0            0            0            0            0            0           0            0            0         0            0          0            0            0          0            0            0            0            0            0          0        0            0         0            0          0            0          0           0          0            0           0          0            0            0           0        0         0            0            0           0            0            0            0            0            0         0            0            0            0            0            0            0         0            0            0          0            0            0         0            0           0            0            0            0            0            0            0            0            0           0          0            0            0          0         0            0            0            0            0           0           0            0            0           0            0           0            0           0            0            0          0            0          0            0            0            0            0            0          0           0            0            0            0           0         0            0            0            0            0            0            0            0            0         0            0         0            0            0            0            0            0            0            0           0            0            0            0            0            0            0          0            0            0          0            0            0            0            0           0         0           0            0            0            0            0            0            0           0           0           1           0         0            0           0            0          0            0         0           0            0            0         0         0         0         0            0            0         0           0            0          1            0            0          0            0         0           0            0            0            0          0            0            0            0            0            0            0            0          0            0            0          0            0         0          0          0          0            0           0            0            0          0            0            0         0            0         0           0            0         0          0          0            0            0         0           0           0            1         0          0            1           0            0         0          0            0           0         0            0            0            0            0           0            0            0            0            0         0          0           0            0            0           0            0           0            0         0            0         0            0            0            0            0            0            0         0            0            0           0            0            0            0           0            0            0            0            0            0         0            0            0            0          0           0            0           0            0            0            0           0           0         0            0            0         0           0            0            0            0            0            0            0           0          0           0            0            0           0         0            0           0            0            0            0            0           0            0            0            0            0        0           0            0            0            0            0            0            0            0            0         1         0           0         0           0            0            0            0          0            0            0            0          0            0           0            0            0           0           0            0           0          0            0          0            0            0          0            0          0         0            0           0          0            0            0          0            0            0            0           0           0            0            0         0            0           0           0            0            0          0            0            0          0            0          0            0            0            0            0           0            0         0            0            0           0            0           0           0            0            0            0            0            0            0            0          0            0            0          0            0            0           0         0         1         0            0            0            0        0            0         0         0            0            0            0            0            0            0           0            0           0            0            0            0            0           0           0         0            0            0            0            0            0            0            1         0            0            0            0          0            0           0            0            0            0            0            0           0            0         0            0            0            0            0            0            0         0            0            0            0           0           0            0            0            0            0           0          0          0            0            0         0            0            0          0           0            0         0            0            0           0            0         0            0            0         0            0            0            0           0            0         0            0          0            0            0            0            0            0        0            0            0            0            1            0            0           0         0            0            0           0            0            0            0         0            0          0            0            0          0            0            0           0           0            0            0            0            0            0            0            0            0           0           0            0           0            0            0          0            0            0            0            0            0           0            0            0            0         0            0         0            0            0            0            0            0            0            0           0            0           0         0            0          0            0          0            0            0            0            0            0            0         1        0           0            0           0            0            0            0            0         0            0            0            0            0           1        0            0          0            0           0            0            0            0            0         0           0           0            0            0           0            0            0         0            0            0           0            0            0         0            0         0           0            1           0            0            0            0            0            0           0            0          0            0            0            0         0            0            0            0           0            0            0         0          0            0            0            0            0            0           0        0           0        0          0         0            0          0            0           0            0            0           0            0            0            0            0            0            0            0           0            0         0            0         0            0           0            0            0         0            0            0            0            1         0            0           0            0           0            0          0            0            0            0            0            0         0         0            1         0         0            0            0            0            0            0          0            0            0            0          0          0            0         0           0         0            0            0            0           0            0         0          0            0            0            0            0            0            0        0            0            0            0         0            0           0         0         0            0         0            0            0           0            0            0            0            0            0         0            0          0            0            0            0            0            0            0            0            0            0           0          0           0            0            0           0           0         0            0            0            0            0         0            0            0            0          0            0          0            0           0            0            0            0           0            0         0            0            0           0            0           0            0            0           0           0            0            0           0            1         0           0            0            0           0            0            0          0            0            0           0            0           0         0         0            0           0            0            0            0            0            0            0            0            0            0            0         0         0        0            0           0         0            0            0          0          0            0            0           0           0           0         0            0            0            0            0            0           0           0          0            0            0            0            0         0            0           0          0            0            0            0            0            0          0            0            0            0            0            0            0            0         0         0            0            0            0            0           0           0          0            0         0         0            0            0         0           0            0            0            0          0           0            0          0            0            0            0            0            0            0            0           0            0            0            0            0            0           0          0         0            0            0          0           0           0            0            0         0         0            0           0         0            0           0            0            0           0            0            0            0            0         0            0            0            0            0            0           0            0           0           1            0            0            0            0            0          0           0            0           0           0            0            0            0            0            0            0            0           0         0            0            0          0        0         0            0            0         0            0            0            0           0            0            0            0           0            0           0            0            0           0           0            0         0            0         0            0           0            0            0            0         0            0         0            0            0            0         0            0            0           0         0            0         0            0           1          0            0          0         0           0        0            0            0          0            0           0           0            0            0           0           0           0            0            0         0            0            0            0           0         0            0        0        0            0            0            0            0         0         0            0           0           0            0         0           0         0         0            0            0            0         0            0          0           0            0         0           0            0            0            0            0            0            0         0            0            0            0            0            0            0           0            0            0            0         0            1            0            0            0            0            0            0            0            0            0            0            0            0           0           0            0          0         0            0            0          0            0            0           0            0            0            0            0            0            0         0          0            0            0          0         0         0          0           0            0           0          0          0            0            0            0            0         0            0            0            0            0          0          0            0            0            0           0            0            0            0            0         0            0          0           0            0         0            0            0           0            0          0            0            0            0            0           0         0            0            0          0            0         0            0           0            0            0            0            0            0            0            0            0           0            0         0            0            0         0            0            0            0            1            0         0            0            0            0           0            0            0         0           0         0            0           0            0            0         0            0            0           0            0          0            0          0            0            0         0          0            0            0          0            0           0         0            0            0            0            0            0            0        0            0            0            0            0           1          0           0            0            0         0            0           0            0            0          0            0            0          0           0            0            0            0          0            0            0            0            0            0            0            0           0            0          0         0            0            0            0            0            0            0            0            0           0            0           0            0         0           0           0            0            0\n",
            "-----------  -----------  --------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ----------  -----------  --------  -----------  --------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  ---------  -----------  -----------  --------  -----------  -----------  ----------  -----------  -----------  -----------  ----------  -----------  ----------  ---------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -------  -----------  -----------  -----------  -----------  ---------  ----------  --------  ---------  ----------  -----------  ----------  ---------  -----------  ----------  -----------  ---------  ---------  ----------  -----------  ----------  ----------  -----------  --------  -----------  -----------  -----------  -----------  --------  -----------  -----------  ---------  ---------  -----------  ---------  -----------  -----------  ----------  ----------  -----------  --------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ---------  ----------  --------  -----------  --------  -----------  -----------  -----------  ----------  --------  ---------  -----------  ----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  --------  ----------  ---------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  ----------  --------  ---------  ----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  --------  -----------  ---------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  ---------  -------  -----------  --------  -----------  ---------  -----------  ---------  ----------  ---------  -----------  ----------  ---------  -----------  -----------  ----------  -------  --------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  ---------  -----------  -----------  --------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ---------  -----------  -----------  ---------  --------  -----------  -----------  -----------  -----------  ----------  ----------  -----------  -----------  ----------  -----------  ----------  -----------  ----------  -----------  -----------  ---------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  ---------  ----------  -----------  -----------  -----------  ----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  ----------  --------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ----------  ----------  ----------  --------  -----------  ----------  -----------  ---------  -----------  --------  ----------  -----------  -----------  --------  --------  --------  --------  -----------  -----------  --------  ----------  -----------  ---------  -----------  -----------  ---------  -----------  --------  ----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  ---------  -----------  --------  ---------  ---------  ---------  -----------  ----------  -----------  -----------  ---------  -----------  -----------  --------  -----------  --------  ----------  -----------  --------  ---------  ---------  -----------  -----------  --------  ----------  ----------  -----------  --------  ---------  -----------  ----------  -----------  --------  ---------  -----------  ----------  --------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  --------  ---------  ----------  -----------  -----------  ----------  -----------  ----------  -----------  --------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  ----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ---------  ----------  -----------  ----------  -----------  -----------  -----------  ----------  ----------  --------  -----------  -----------  --------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ---------  ----------  -----------  -----------  ----------  --------  -----------  ----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  --------  ----------  --------  ----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  ---------  -----------  ----------  -----------  -----------  ----------  ----------  -----------  ----------  ---------  -----------  ---------  -----------  -----------  ---------  -----------  ---------  --------  -----------  ----------  ---------  -----------  -----------  ---------  -----------  -----------  -----------  ----------  ----------  -----------  -----------  --------  -----------  ----------  ----------  -----------  -----------  ---------  -----------  -----------  ---------  -----------  ---------  -----------  -----------  -----------  -----------  ----------  -----------  --------  -----------  -----------  ----------  -----------  ----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  ---------  -----------  -----------  ----------  --------  --------  --------  -----------  -----------  -----------  -------  -----------  --------  --------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ----------  -----------  -----------  -----------  -----------  ----------  ----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ---------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ----------  ----------  -----------  -----------  -----------  -----------  ----------  ---------  ---------  -----------  -----------  --------  -----------  -----------  ---------  ----------  -----------  --------  -----------  -----------  ----------  -----------  --------  -----------  -----------  --------  -----------  -----------  -----------  ----------  -----------  --------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  --------  -----------  -----------  ----------  -----------  -----------  -----------  --------  -----------  ---------  -----------  -----------  ---------  -----------  -----------  ----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ----------  -----------  ----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  --------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ----------  --------  -----------  ---------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -------  ----------  -----------  ----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  ----------  -------  -----------  ---------  -----------  ----------  -----------  -----------  -----------  -----------  --------  ----------  ----------  -----------  -----------  ----------  -----------  -----------  --------  -----------  -----------  ----------  -----------  -----------  --------  -----------  --------  ----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ---------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ----------  -----------  -----------  --------  ---------  -----------  -----------  -----------  -----------  -----------  ----------  -------  ----------  -------  ---------  --------  -----------  ---------  -----------  ----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  --------  -----------  --------  -----------  ----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  --------  -----------  ----------  -----------  ----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  --------  --------  -----------  --------  --------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  ---------  ---------  -----------  --------  ----------  --------  -----------  -----------  -----------  ----------  -----------  --------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -------  -----------  -----------  -----------  --------  -----------  ----------  --------  --------  -----------  --------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ---------  ----------  -----------  -----------  ----------  ----------  --------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ---------  -----------  ---------  -----------  ----------  -----------  -----------  -----------  ----------  -----------  --------  -----------  -----------  ----------  -----------  ----------  -----------  -----------  ----------  ----------  -----------  -----------  ----------  -----------  --------  ----------  -----------  -----------  ----------  -----------  -----------  ---------  -----------  -----------  ----------  -----------  ----------  --------  --------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  --------  -------  -----------  ----------  --------  -----------  -----------  ---------  ---------  -----------  -----------  ----------  ----------  ----------  --------  -----------  -----------  -----------  -----------  -----------  ----------  ----------  ---------  -----------  -----------  -----------  -----------  --------  -----------  ----------  ---------  -----------  -----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  --------  -----------  -----------  -----------  -----------  ----------  ----------  ---------  -----------  --------  --------  -----------  -----------  --------  ----------  -----------  -----------  -----------  ---------  ----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  ----------  ---------  --------  -----------  -----------  ---------  ----------  ----------  -----------  -----------  --------  --------  -----------  ----------  --------  -----------  ----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ----------  ----------  -----------  -----------  -----------  -----------  -----------  ---------  ----------  -----------  ----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  --------  -----------  -----------  ---------  -------  --------  -----------  -----------  --------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  ----------  -----------  ----------  -----------  -----------  ----------  ----------  -----------  --------  -----------  --------  -----------  ----------  -----------  -----------  -----------  --------  -----------  --------  -----------  -----------  -----------  --------  -----------  -----------  ----------  --------  -----------  --------  -----------  ----------  ---------  -----------  ---------  --------  ----------  -------  -----------  -----------  ---------  -----------  ----------  ----------  -----------  -----------  ----------  ----------  ----------  -----------  -----------  --------  -----------  -----------  -----------  ----------  --------  -----------  -------  -------  -----------  -----------  -----------  -----------  --------  --------  -----------  ----------  ----------  -----------  --------  ----------  --------  --------  -----------  -----------  -----------  --------  -----------  ---------  ----------  -----------  --------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  ----------  -----------  ---------  --------  -----------  -----------  ---------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  --------  ---------  -----------  -----------  ---------  --------  --------  ---------  ----------  -----------  ----------  ---------  ---------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  -----------  ---------  ---------  -----------  -----------  -----------  ----------  -----------  -----------  -----------  -----------  --------  -----------  ---------  ----------  -----------  --------  -----------  -----------  ----------  -----------  ---------  -----------  -----------  -----------  -----------  ----------  --------  -----------  -----------  ---------  -----------  --------  -----------  ----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  --------  -----------  -----------  --------  -----------  -----------  -----------  -----------  -----------  --------  -----------  -----------  -----------  ----------  -----------  -----------  --------  ----------  --------  -----------  ----------  -----------  -----------  --------  -----------  -----------  ----------  -----------  ---------  -----------  ---------  -----------  -----------  --------  ---------  -----------  -----------  ---------  -----------  ----------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -------  -----------  -----------  -----------  -----------  ----------  ---------  ----------  -----------  -----------  --------  -----------  ----------  -----------  -----------  ---------  -----------  -----------  ---------  ----------  -----------  -----------  -----------  ---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ---------  --------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------  -----------  ----------  -----------  --------  ----------  ----------  -----------  -----------  -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cXhARUu8S6S",
        "outputId": "9c8f03a5-346a-4a7e-d283-894dbc795496"
      },
      "source": [
        "index = np.where(probs_table[1,:] != 1)[0]\n",
        "np.mean(probs_table[0,index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06791542386186844"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqse4AeIhFsP"
      },
      "source": [
        "**Graphs for Thesis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PD8pFf_VOdI"
      },
      "source": [
        "Partial Dependence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "R34tLhy249Ia",
        "outputId": "13d1e1b3-5f11-42e9-fdb4-54ead37691a0"
      },
      "source": [
        "# https://scikit-learn.org/stable/inspection.html\n",
        "\n",
        "names = [\"Placement\",\"Sub-Class\",\"Class Code\",\"Leader Status\",\"Broker\",\"Years Held\"\n",
        "          ,\"Policy Length\",\"World Bank\",\"IHS Markit\",\"Limit\",\"Gross Written Premium\"\n",
        "          ,\"Exposure\",\"Leader Line %\",\"Excess\",\"Deductible\",\"PLR\",\"RARC\",\"Gross Model Price\"\n",
        "          ,\"Gross Technical Price\",\"Pricing Strength\",\"Pricing Strength 2\",\"Broker Fee\"\n",
        "          ,\"Attachment\",\"Model to Actual Ratio\",\"Model to Technical Ratio\",\"PLR ex Adj\"]\n",
        "\n",
        "# X{array-like or dataframe} of shape (n_samples, n_features)\n",
        "mc_clf = GradientBoostingClassifier(n_estimators=100,max_depth=1).fit(original_policies[:,: -1], original_policies[:, -1])\n",
        "features = [6,7,8,9,10,11,17,18,21] # The target features for which to create the PDPs\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "plot_partial_dependence(mc_clf, original_policies[:,: -1], features,ax = ax, feature_names = names) # target ignored in binary classification settings.\n",
        "plt.savefig('partial_dependence.png')\n",
        "\n",
        "# (6) World bank, (8) Limit, (9) GNWP, (10) GGWP, (15) PLR, (17) Gross Gross Model Price, (18) Gross Net Model Price, (19) Technical Price, (23) Broker Fee, (24) Attachment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC6eei5jh0P_"
      },
      "source": [
        "# training a variational auto encoder based on keras tutorial https://blog.keras.io/building-autoencoders-in-keras.html\n",
        "\n",
        "original_dim = all_policies.shape[1] - 1\n",
        "intermediate_dim = 10\n",
        "latent_dim = 4\n",
        "\n",
        "inputs = keras.Input(shape=(original_dim,))\n",
        "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
        "z_mean = layers.Dense(latent_dim)(h)\n",
        "z_log_sigma = layers.Dense(latent_dim)(h)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),mean=0., stddev=0.1)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
        "\n",
        "# Create encoder\n",
        "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "\n",
        "# Create decoder\n",
        "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
        "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
        "\n",
        "#reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
        "reconstruction_loss = keras.losses.mean_squared_error(inputs, outputs)\n",
        "reconstruction_loss *= original_dim\n",
        "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "# fit the VAE\n",
        "vae.fit(claim_policies[:,:-1], claim_policies[:,:-1],epochs=500,batch_size=20)\n",
        "\n",
        "# create synthetic data\n",
        "n = 2\n",
        "grid_x = np.linspace(-1, 1, n)\n",
        "grid_y = np.linspace(-1, 1, n)\n",
        "grid_z = np.linspace(-1, 1, n)\n",
        "grid_t = np.linspace(-1, 1, n)\n",
        "\n",
        "synthetic_data = np.zeros((n**4,all_policies.shape[1] - 1))\n",
        "\n",
        "k = 0\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "      for z, zi in enumerate(grid_z):\n",
        "        for t, ti in enumerate(grid_t):\n",
        "          z_sample = np.array([[xi, yi, zi, ti]])\n",
        "          x_decoded = decoder.predict(z_sample)\n",
        "          synthetic_data[k,:] = x_decoded[0]\n",
        "          k += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "ogpx7ZwFjsqD",
        "outputId": "07538485-98bb-4708-c9bf-2e53cb1fbe3c"
      },
      "source": [
        "# comparing synthesised claim policies against actual claim policies\n",
        "\n",
        "# CTGAN\n",
        "#discrete_columns = [0,1,2,3,4,5,26]\n",
        "#with warnings.catch_warnings():\n",
        "#    warnings.filterwarnings(\"ignore\")\n",
        "#    ctgan = CTGANSynthesizer(epochs=50)\n",
        "#    ctgan.fit(claim_policies, discrete_columns)\n",
        "#    synthetic_data = ctgan.sample(100)\n",
        "\n",
        "# SMOTE\n",
        "#undersample = RandomUnderSampler(sampling_strategy=1)\n",
        "#X_resampled, y_resampled = undersample.fit_resample(original_policies[:,: -1], original_policies[:,-1])\n",
        "#X_synthetic, Y_synthetic = SMOTE().fit_resample(X_resampled, y_resampled)\n",
        "#synthetic_data = np.append(X_synthetic,np.expand_dims(Y_synthetic,axis=1),axis=1)\n",
        "\n",
        "# VAE\n",
        "synthetic_data = np.append(synthetic_data,np.ones((synthetic_data.shape[0],1)),axis=1)\n",
        "\n",
        "# All\n",
        "# synthesised claim polcies are set to 0 label (dark blue)\n",
        "dummy_synthetic_data = np.copy(synthetic_data)\n",
        "index = np.where(dummy_synthetic_data[:,-1] == 1)\n",
        "dummy_synthetic_data = dummy_synthetic_data[index[0],:]\n",
        "dummy_synthetic_data[:,-1] = 0\n",
        "mix_claim_policies = np.append(claim_policies[:,:-1],dummy_synthetic_data[:,:-1],axis=0)\n",
        "mix_y = np.append(claim_policies[:,-1],dummy_synthetic_data[:,-1])\n",
        "\n",
        "# undersample majority class to make graphical comparison easier \n",
        "undersample = RandomUnderSampler(sampling_strategy=1)\n",
        "X_PCA, y_PCA = undersample.fit_resample(mix_claim_policies, mix_y)\n",
        "\n",
        "shuffle = np.arange((X_PCA.shape[0]))\n",
        "np.random.shuffle(shuffle)\n",
        "X_PCA = X_PCA[shuffle,:]\n",
        "y_PCA = y_PCA[shuffle]\n",
        "\n",
        "# fit and transform PCA\n",
        "features = [\"1\", \"2\", \"3\"]\n",
        "n_components = 3\n",
        "pca = PCA(n_components=n_components)\n",
        "pca.fit(mix_claim_policies)\n",
        "components = pca.fit_transform(X_PCA)\n",
        "labels = y_PCA.T \n",
        "\n",
        "# plot graphs\n",
        "fig = px.scatter_matrix(components,labels=labels,dimensions=range(n_components),color=labels)\n",
        "fig.update_traces(diagonal_visible=False)\n",
        "fig.write_image(\"PCA_plot_VAE.png\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_core.py:79: FutureWarning:\n",
            "\n",
            "Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"4d070800-6b9f-4b44-9d18-dcd45e2de84a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"4d070800-6b9f-4b44-9d18-dcd45e2de84a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '4d070800-6b9f-4b44-9d18-dcd45e2de84a',\n",
              "                        [{\"diagonal\": {\"visible\": false}, \"dimensions\": [{\"axis\": {\"matches\": true}, \"label\": \"0\", \"values\": [-0.5341784954158741, 0.1851929825576275, 0.17281168692440194, -0.6939893862766264, -0.3872415750248477, -0.3804225203822133, -0.025956641715955048, -0.22303478197338117, -0.1935431626368483, -0.27033256668264166, -0.5395301699677552, -0.21715448708835025, 0.7809096155276313, -0.20565451804123436, 0.33684903676849687, 0.48466332259823314, -0.4898499948905889, 0.9012383727280169, 0.3225574909633825, 0.1685478600794821, 0.5410780098594857, -0.6925509087312439, -0.7139023142395606, 1.1835960165147836, 0.3774336088504983, -0.681887990730352, 0.3579531370614132, 0.343682741736509, 0.12709873567684762, 0.17630030380375422, -0.37111741052034597, 0.16043400266725422]}, {\"axis\": {\"matches\": true}, \"label\": \"1\", \"values\": [-0.3635229512797146, -0.4050124642652429, 0.3443705439384883, -0.3968198969496217, 0.07751193302665665, -0.044499662999968985, 0.1940857418830742, 0.029955403475339287, -0.010862816355637614, -0.2569672500342556, 0.23901144036811744, -0.036879980550487974, -0.3978317576584098, 0.12563888200775175, 0.40935092264395784, 0.5288683266744243, -0.2086826753356088, -0.7105298033470098, -0.10490102528952547, 0.2776353239275786, 0.2280701431678548, -0.14695341814849164, -0.3137295457894043, -0.7424149225887849, 0.0947889978384405, -0.2519881944391978, -0.2398941400886194, 0.8336334594922082, 0.33685093384254805, 0.36366112031289316, 0.16169462789074446, 0.38636270462990385]}, {\"axis\": {\"matches\": true}, \"label\": \"2\", \"values\": [0.4305925146162689, -0.03706144806336737, 0.02838246880136686, -0.018201711766457705, 0.012971655140846952, -0.5201280954521973, 0.20164301993957054, -0.024792411952755875, 0.2078103250174026, -0.23836834993821251, -0.46975159924365545, 0.24190495487178906, 0.34982228298445284, -0.19109162071294755, 0.18189853123932323, -0.4136629339263928, -0.03819503636021133, -0.4537420436117279, 0.18887379119747078, 0.47071619204665655, 0.3222531384324352, -0.16926093161762804, -0.1056154727985879, -0.39781756944854607, 0.7065190936977946, 0.2814114907515787, 0.13607698566975632, -0.3469173790156528, -0.13368756473156398, -0.04465798728351586, -0.05188726101994643, -0.10603702746334502]}], \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}<br>color=%{marker.color}\", \"legendgroup\": \"\", \"marker\": {\"color\": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], \"coloraxis\": \"coloraxis\", \"symbol\": \"circle\"}, \"name\": \"\", \"showlegend\": false, \"type\": \"splom\"}],\n",
              "                        {\"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"color\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"dragmode\": \"select\", \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4d070800-6b9f-4b44-9d18-dcd45e2de84a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}